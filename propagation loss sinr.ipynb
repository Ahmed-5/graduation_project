{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d559492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21eb46de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50400 14400]\n",
      " [10800 14400]\n",
      " [21600 14400]\n",
      " [50400 14400]\n",
      " [21600 14400]\n",
      " [50400 14400]\n",
      " [50400 14400]\n",
      " [50400 14400]\n",
      " [21600 14400]\n",
      " [21600 14400]\n",
      " [21600 14400]\n",
      " [10800 14400]\n",
      " [50400 14400]\n",
      " [21600 14400]\n",
      " [10800 14400]\n",
      " [50400 14400]\n",
      " [21600 14400]\n",
      " [10800 14400]\n",
      " [21600 14400]\n",
      " [21600 14400]\n",
      " [10800 14400]\n",
      " [21600 14400]\n",
      " [50400 14400]\n",
      " [10800 14400]\n",
      " [50400 14400]]\n"
     ]
    }
   ],
   "source": [
    "blackout_choices = np.array([\n",
    "    [3*3600, 4*3600],\n",
    "    [6*3600, 4*3600],\n",
    "    [14*3600, 4*3600],\n",
    "    [19*3600, 4*3600],\n",
    "])\n",
    "\n",
    "fc = 2.6 #2.6 GHz\n",
    "bandwidth = 1e7 #10 MHz\n",
    "temp = 40 + 273.15 # 40 celsius in kelvin\n",
    "boltz = 1.381e-23\n",
    "epsilon = 1e-7\n",
    "row_bs = 5\n",
    "col_bs = 5\n",
    "grid_width = 2000 + 1000*row_bs\n",
    "grid_height = 2000 + 1000*col_bs\n",
    "bs_loc = np.mgrid[1000:grid_width-1000:1000, 1000:grid_height-1000:1000]\n",
    "bs_loc = bs_loc.reshape((2,-1)).T\n",
    "bs_loc += 100 - np.random.randint(0, 200, bs_loc.shape)\n",
    "\n",
    "bs_power = np.array([40. for i in bs_loc])\n",
    "\n",
    "bs_blackout = blackout_choices[np.random.randint(0,3, (row_bs*col_bs))]\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self, bs_loc, bs_power, bs_blackouts, max_power, min_power, n_actions, grid_width, grid_height, n_nearest):\n",
    "        self.bs_loc = bs_loc\n",
    "        self.bs_power = bs_power\n",
    "        self.electricity = np.zeros_like(bs_power)\n",
    "        self.bs_blackout_start = bs_blackouts[:,0]\n",
    "        self.bs_blackout_end = np.sum(bs_blackouts, axis=-1)\n",
    "        self.apply_blackouts(0)\n",
    "        self.max_power = max_power # in watt\n",
    "        self.min_power = min_power\n",
    "        self.n_actions = n_actions\n",
    "        self.grid_width = grid_width\n",
    "        self.grid_height = grid_height\n",
    "        self.points = np.mgrid[0:grid_width, 0:grid_height]\n",
    "        self.points = np.stack(self.points, axis=-1)\n",
    "        self.powers = self.power_grid(self.bs_loc, self.bs_power, self.points)\n",
    "        self.bit_rate = self.bit_rate_from_grid()\n",
    "        self.reward = self.get_reward()\n",
    "        self.actions = self.watt_to_dbm(np.linspace(min_power, max_power, n_actions))\n",
    "        self.n_nearest = min(n_nearest, bs_power.shape[0])\n",
    "        self.n_bs = bs_power.shape[0]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_input_dim(self):\n",
    "        return self.n_nearest*4 # after adding has electricity attrib 3 will be changed to 4\n",
    "    \n",
    "    def get_output_dim(self):\n",
    "        return self.n_actions\n",
    "    \n",
    "    def apply_blackouts(self, time):\n",
    "        self.electricity = (time>=self.bs_blackout_start) & (time<=self.bs_blackout_end)\n",
    "    \n",
    "    def make_action(self, bs_index, action):\n",
    "        state = self.get_state(bs_index) \n",
    "        self.bs_power[bs_index] = self.actions[action]\n",
    "        self.powers = self.power_grid(self.bs_loc, self.bs_power, self.points)\n",
    "        self.bit_rate = self.bit_rate_from_grid()\n",
    "        next_state = self.get_state(bs_index)\n",
    "        reward = self.get_reward()\n",
    "        return state, action, next_state, reward\n",
    "        \n",
    "    def watt_to_dbm(self, watt):\n",
    "        return 10*np.log10(1000*watt)\n",
    "\n",
    "    def dbm_to_watt(self, dbm):\n",
    "        return np.power(10, dbm/10)/1000\n",
    "\n",
    "    def path_loss(self, distance, frequency=fc):\n",
    "    #     return 36.7*np.log10(distance) + 47.7 + 26*np.log10(frequency)\n",
    "        return 35*np.log10(distance) + 35.7\n",
    "\n",
    "    def power_grid(self, bs_loc, bs_power, points):\n",
    "        powers = []\n",
    "        for loc, power in zip(bs_loc, bs_power):\n",
    "            distance = np.linalg.norm(loc - points+epsilon, axis=-1)\n",
    "            powers.append(power - self.path_loss(distance))\n",
    "        return np.stack(powers, axis=-1)\n",
    "\n",
    "    def get_bit_rate_sinr(self, signal, interference, bandwidth=bandwidth, temp=temp):\n",
    "        return bandwidth*np.log10(1+ (signal/(interference + temp*boltz*bandwidth)))\n",
    "    \n",
    "    def bit_rate_from_grid(self):\n",
    "        max_power = self.dbm_to_watt(self.powers.max(axis=-1))\n",
    "        interference_power = self.dbm_to_watt(self.powers).sum(axis=-1) - max_power\n",
    "        return self.get_bit_rate_sinr(max_power, interference_power)\n",
    "\n",
    "    def bit_rate_cost_function(self, b_rate):\n",
    "        total_points = 1\n",
    "        for i in b_rate.shape:\n",
    "            total_points *= i\n",
    "\n",
    "        under_1mb = b_rate<(1024**2)*8\n",
    "        under_1mb = under_1mb.sum()\n",
    "        min_speed = b_rate.min()/(1024*1024*8) #1MB\n",
    "        return 10*under_1mb/total_points + 1/(min_speed+epsilon)\n",
    "\n",
    "    def get_reward(self):\n",
    "        return 10 - self.bit_rate_cost_function(self.bit_rate) - np.inner(self.electricity, self.dbm_to_watt(self.bs_power))\n",
    "    \n",
    "    def get_state(self, bs_index):\n",
    "        x,y = self.bs_loc[bs_index]\n",
    "        powers = self.powers[np.round(x),np.round(y),:].reshape(-1)\n",
    "        indecies = np.argsort(powers)[::-1][:self.n_nearest]\n",
    "        bs_index_posistion = np.where(indecies == bs_index)[0]\n",
    "        \n",
    "        if bs_index_posistion.size > 0:\n",
    "            indecies = np.delete(indecies, bs_index_posistion)\n",
    "            indecies = indecies[:self.n_nearest]\n",
    "        else:\n",
    "            indecies = indecies[:self.n_nearest-1]\n",
    "            \n",
    "        bs_power = powers[bs_index]\n",
    "        state = np.array([powers[bs_index], self.electricity[bs_index], 0, 0])\n",
    "        nearest_powers = powers[np.array(indecies)]\n",
    "        nearest_elec = self.electricity[np.array(indecies)]\n",
    "        diff =  self.bs_loc[np.array(indecies)] - self.bs_loc[bs_index]\n",
    "        nearest_distances = np.linalg.norm(diff, axis=-1)\n",
    "        nearest_angles = np.arctan2(diff[:,1].reshape(-1), diff[:,0].reshape(-1))\n",
    "        \n",
    "        return np.hstack((state, np.stack([nearest_powers, nearest_elec,\n",
    "                                           nearest_distances, nearest_angles], axis=-1).reshape(-1)))\n",
    "    \n",
    "    def plot_bit_rate(self):\n",
    "        plt.contourf(self.points[:,:,0], self.points[:,:,1], self.bit_rate, 100, cmap = plt.cm.jet)\n",
    "        \n",
    "    def plot_log_bit_rate(self):\n",
    "        plt.contourf(self.points[:,:,0], self.points[:,:,1], self.bit_rate, 100, cmap = plt.cm.jet)\n",
    "        \n",
    "    def plot_power_grid(self):\n",
    "        plt.contourf(self.points[:,:,0], self.points[:,:,1], self.bit_rate, 100, cmap = plt.cm.jet)\n",
    "        \n",
    "    def plot_log_power_grid(self):\n",
    "        plt.contourf(self.points[:,:,0], self.points[:,:,1], self.bit_rate, 100, cmap = plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a7311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module): # ready\n",
    "    def __init__(self, n_inputs, n_actions):\n",
    "        nn.Module.__init__(self)\n",
    "        self.fc1 = nn.Linear(in_features=n_inputs, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=n_actions)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2efd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple(\n",
    "    \"Experience\", (\"state\", \"action\", \"next_state\", \"reward\")) # ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278da5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(): # ready\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "\n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "        self.push_count += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c69e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy(): # ready\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "\n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) * np.exp(-1. * current_step * self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11c365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = self.strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "\n",
    "        if rate > random.random():\n",
    "            action = random.randrange(self.num_actions)\n",
    "            return torch.tensor([action])\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1943cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QValues():\n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        return policy_net(states).gather(dim=1, index=actions.unsqueeze(-1))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_next(target_net, next_states):\n",
    "        values = target_net(next_states).max(dim=1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6978e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title(\"Training...\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Duration\")\n",
    "    plt.plot(values)\n",
    "\n",
    "    moving_avg = get_moving_avg(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)\n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values), \"\\n\", moving_avg_period,\n",
    "          \"episode moving avg:\", moving_avg[-1])\n",
    "#     if is_ipython:\n",
    "#         display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f80636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moving_avg(period, values):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0, size=period, step=1).mean(\n",
    "            dim=1).flatten(start_dim=0)\n",
    "    else:\n",
    "        moving_avg = torch.zeros_like(values)\n",
    "    return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efe6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(exps):\n",
    "    batch = Experience(*zip(*exps))\n",
    "    \n",
    "    t1 = torch.cat(batch.state)\n",
    "    t2 = torch.cat(batch.action)\n",
    "    t3 = torch.cat(batch.next_state)\n",
    "    t4 = torch.cat(batch.reward)\n",
    "\n",
    "    return (t1, t2, t3, t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b4c6c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-ffc16bea6665>:53: RuntimeWarning: divide by zero encountered in log10\n",
      "  return 10*np.log10(1000*watt)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "gamma = 0.7\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.001\n",
    "target_update = 10\n",
    "memory_size = 1000\n",
    "lr = 0.001\n",
    "num_episodes = 5000\n",
    "\n",
    "env = Environment(bs_loc, bs_power, bs_blackout,10, 0, 11, grid_width, grid_height, 4)\n",
    "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
    "agent = Agent(strategy, env.get_output_dim())\n",
    "memory = ReplayMemory(memory_size)\n",
    "\n",
    "policy_net = DQN(env.get_input_dim(), env.get_output_dim())\n",
    "target_net = DQN(env.get_input_dim(), env.get_output_dim())\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7637541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPISODE: 1\n",
      "EPISODE DONE IN 2.23905348777771 SECONDS, reward -6.396927833557129, action 1\n",
      "EPISODE DONE IN 4.365621089935303 SECONDS, reward -5.2661213874816895, action 0\n",
      "EPISODE DONE IN 6.494985342025757 SECONDS, reward -4.774501800537109, action 4\n",
      "EPISODE DONE IN 8.61030101776123 SECONDS, reward -4.890564918518066, action 6\n",
      "\n",
      "\n",
      "EPISODE: 2\n",
      "EPISODE DONE IN 2.619133710861206 SECONDS, reward -3.396500587463379, action 0\n",
      "EPISODE DONE IN 4.743169546127319 SECONDS, reward -4.494022846221924, action 6\n",
      "EPISODE DONE IN 6.874470233917236 SECONDS, reward -4.494022846221924, action 4\n",
      "EPISODE DONE IN 8.998049974441528 SECONDS, reward -3.2858059406280518, action 7\n",
      "\n",
      "\n",
      "EPISODE: 3\n",
      "EPISODE DONE IN 2.218256711959839 SECONDS, reward -8.70699405670166, action 5\n",
      "EPISODE DONE IN 4.426408529281616 SECONDS, reward -8.042205810546875, action 3\n",
      "EPISODE DONE IN 6.677329778671265 SECONDS, reward -7.619953155517578, action 6\n",
      "EPISODE DONE IN 8.898887872695923 SECONDS, reward -8.285063743591309, action 4\n",
      "\n",
      "\n",
      "EPISODE: 4\n",
      "EPISODE DONE IN 2.2155067920684814 SECONDS, reward -5.132402420043945, action 1\n",
      "EPISODE DONE IN 4.425277471542358 SECONDS, reward -5.012288570404053, action 2\n",
      "EPISODE DONE IN 6.6407623291015625 SECONDS, reward -4.59523344039917, action 3\n",
      "EPISODE DONE IN 8.859089851379395 SECONDS, reward -4.735631942749023, action 5\n",
      "\n",
      "\n",
      "EPISODE: 5\n",
      "EPISODE DONE IN 2.274717330932617 SECONDS, reward -4.091862201690674, action 2\n",
      "EPISODE DONE IN 4.511942148208618 SECONDS, reward -5.07246732711792, action 7\n",
      "EPISODE DONE IN 6.891582727432251 SECONDS, reward -4.427534580230713, action 6\n",
      "EPISODE DONE IN 9.147388219833374 SECONDS, reward -5.938267707824707, action 0\n",
      "\n",
      "\n",
      "EPISODE: 6\n",
      "EPISODE DONE IN 2.1471636295318604 SECONDS, reward -11.15576457977295, action 6\n",
      "EPISODE DONE IN 4.2712788581848145 SECONDS, reward -11.15576457977295, action 7\n",
      "EPISODE DONE IN 6.398609399795532 SECONDS, reward -11.302741050720215, action 1\n",
      "EPISODE DONE IN 8.50806999206543 SECONDS, reward -11.302741050720215, action 0\n",
      "\n",
      "\n",
      "EPISODE: 7\n",
      "EPISODE DONE IN 2.0248825550079346 SECONDS, reward -10.50883960723877, action 0\n",
      "EPISODE DONE IN 4.041656255722046 SECONDS, reward -8.778457641601562, action 8\n",
      "EPISODE DONE IN 6.068703889846802 SECONDS, reward -8.778457641601562, action 1\n",
      "EPISODE DONE IN 8.184310913085938 SECONDS, reward -5.063669204711914, action 6\n",
      "\n",
      "\n",
      "EPISODE: 8\n",
      "EPISODE DONE IN 2.2112507820129395 SECONDS, reward -6.412753582000732, action 2\n",
      "EPISODE DONE IN 4.419330596923828 SECONDS, reward -5.905059337615967, action 1\n",
      "EPISODE DONE IN 6.542121887207031 SECONDS, reward -16.707550048828125, action 0\n",
      "EPISODE DONE IN 8.648847579956055 SECONDS, reward -19.49800682067871, action 3\n",
      "\n",
      "\n",
      "EPISODE: 9\n",
      "EPISODE DONE IN 2.120720148086548 SECONDS, reward -11.449684143066406, action 5\n",
      "EPISODE DONE IN 4.231957674026489 SECONDS, reward -9.289855003356934, action 7\n",
      "EPISODE DONE IN 6.451101064682007 SECONDS, reward -7.306107521057129, action 2\n",
      "EPISODE DONE IN 8.654491662979126 SECONDS, reward -8.120824813842773, action 8\n",
      "\n",
      "\n",
      "EPISODE: 10\n",
      "EPISODE DONE IN 2.208552598953247 SECONDS, reward -11.34104061126709, action 8\n",
      "EPISODE DONE IN 4.413437128067017 SECONDS, reward -11.22091293334961, action 8\n",
      "EPISODE DONE IN 6.689534902572632 SECONDS, reward -11.827991485595703, action 6\n",
      "EPISODE DONE IN 8.8946053981781 SECONDS, reward -11.21605396270752, action 4\n",
      "\n",
      "\n",
      "EPISODE: 11\n",
      "EPISODE DONE IN 2.2103259563446045 SECONDS, reward -7.975915431976318, action 5\n",
      "EPISODE DONE IN 4.42241358757019 SECONDS, reward -8.81192684173584, action 5\n",
      "EPISODE DONE IN 6.635016202926636 SECONDS, reward -8.50634765625, action 7\n",
      "EPISODE DONE IN 8.83601999282837 SECONDS, reward -8.730403900146484, action 3\n",
      "\n",
      "\n",
      "EPISODE: 12\n",
      "EPISODE DONE IN 2.21144437789917 SECONDS, reward -11.721944808959961, action 8\n",
      "EPISODE DONE IN 4.410377264022827 SECONDS, reward -11.721944808959961, action 5\n",
      "EPISODE DONE IN 6.5276994705200195 SECONDS, reward -12.12598705291748, action 0\n",
      "EPISODE DONE IN 8.637110948562622 SECONDS, reward -12.751599311828613, action 8\n",
      "\n",
      "\n",
      "EPISODE: 13\n",
      "EPISODE DONE IN 2.1237614154815674 SECONDS, reward -12.477965354919434, action 6\n",
      "EPISODE DONE IN 4.24467921257019 SECONDS, reward -12.556546211242676, action 1\n",
      "EPISODE DONE IN 6.612415790557861 SECONDS, reward -11.247386932373047, action 1\n",
      "EPISODE DONE IN 8.771187782287598 SECONDS, reward -11.203621864318848, action 0\n",
      "\n",
      "\n",
      "EPISODE: 14\n",
      "EPISODE DONE IN 2.124229907989502 SECONDS, reward -18.909191131591797, action 2\n",
      "EPISODE DONE IN 4.262772798538208 SECONDS, reward -7.302890777587891, action 5\n",
      "EPISODE DONE IN 6.51475977897644 SECONDS, reward -7.808166027069092, action 4\n",
      "EPISODE DONE IN 8.736443519592285 SECONDS, reward -4.108156681060791, action 7\n",
      "\n",
      "\n",
      "EPISODE: 15\n",
      "EPISODE DONE IN 2.21917462348938 SECONDS, reward -10.909695625305176, action 7\n",
      "EPISODE DONE IN 4.42525053024292 SECONDS, reward -13.153892517089844, action 1\n",
      "EPISODE DONE IN 6.646096467971802 SECONDS, reward -13.63202953338623, action 8\n",
      "EPISODE DONE IN 8.851215124130249 SECONDS, reward -12.670096397399902, action 1\n",
      "\n",
      "\n",
      "EPISODE: 16\n",
      "EPISODE DONE IN 2.224395751953125 SECONDS, reward -6.0563578605651855, action 2\n",
      "EPISODE DONE IN 4.430811405181885 SECONDS, reward -6.206780910491943, action 5\n",
      "EPISODE DONE IN 6.648010015487671 SECONDS, reward -5.989967346191406, action 4\n",
      "EPISODE DONE IN 8.857750177383423 SECONDS, reward -3.936372995376587, action 8\n",
      "\n",
      "\n",
      "EPISODE: 17\n",
      "EPISODE DONE IN 2.1317222118377686 SECONDS, reward -2.372248888015747, action 0\n",
      "EPISODE DONE IN 4.273096084594727 SECONDS, reward -2.509451150894165, action 6\n",
      "EPISODE DONE IN 6.422997951507568 SECONDS, reward -2.6799919605255127, action 6\n",
      "EPISODE DONE IN 8.552058219909668 SECONDS, reward -4.858114719390869, action 1\n",
      "\n",
      "\n",
      "EPISODE: 18\n",
      "EPISODE DONE IN 2.2189512252807617 SECONDS, reward -4.8853535652160645, action 1\n",
      "EPISODE DONE IN 4.431459426879883 SECONDS, reward -4.8853535652160645, action 6\n",
      "EPISODE DONE IN 6.651849985122681 SECONDS, reward -4.823846817016602, action 5\n",
      "EPISODE DONE IN 8.861951351165771 SECONDS, reward -5.050793170928955, action 3\n",
      "\n",
      "\n",
      "EPISODE: 19\n",
      "EPISODE DONE IN 2.222788095474243 SECONDS, reward -8.008055686950684, action 5\n",
      "EPISODE DONE IN 4.429915904998779 SECONDS, reward -8.262190818786621, action 5\n",
      "EPISODE DONE IN 6.642683982849121 SECONDS, reward -8.498441696166992, action 6\n",
      "EPISODE DONE IN 8.8428955078125 SECONDS, reward -8.244668006896973, action 2\n",
      "\n",
      "\n",
      "EPISODE: 20\n",
      "EPISODE DONE IN 2.211397647857666 SECONDS, reward -9.258460998535156, action 6\n",
      "EPISODE DONE IN 4.323185443878174 SECONDS, reward -11.734502792358398, action 0\n",
      "EPISODE DONE IN 6.437780380249023 SECONDS, reward -13.06188678741455, action 5\n",
      "EPISODE DONE IN 8.546830892562866 SECONDS, reward -10.014535903930664, action 8\n",
      "\n",
      "\n",
      "EPISODE: 21\n",
      "EPISODE DONE IN 2.121187210083008 SECONDS, reward -4.871051788330078, action 1\n",
      "EPISODE DONE IN 4.325251340866089 SECONDS, reward -5.675102710723877, action 6\n",
      "EPISODE DONE IN 6.541993856430054 SECONDS, reward -5.500567436218262, action 4\n",
      "EPISODE DONE IN 8.753422975540161 SECONDS, reward -5.60210657119751, action 7\n",
      "\n",
      "\n",
      "EPISODE: 22\n",
      "EPISODE DONE IN 2.2142603397369385 SECONDS, reward -10.654165267944336, action 7\n",
      "EPISODE DONE IN 4.332724332809448 SECONDS, reward -12.136327743530273, action 0\n",
      "EPISODE DONE IN 6.4561474323272705 SECONDS, reward -12.330410957336426, action 5\n",
      "EPISODE DONE IN 8.570042848587036 SECONDS, reward -14.852487564086914, action 1\n",
      "\n",
      "\n",
      "EPISODE: 23\n",
      "EPISODE DONE IN 2.003964900970459 SECONDS, reward -4.462901592254639, action 0\n",
      "EPISODE DONE IN 4.120259523391724 SECONDS, reward -5.545126914978027, action 8\n",
      "EPISODE DONE IN 6.2391884326934814 SECONDS, reward -10.441166877746582, action 3\n",
      "EPISODE DONE IN 8.353977918624878 SECONDS, reward -11.429988861083984, action 3\n",
      "\n",
      "\n",
      "EPISODE: 24\n",
      "EPISODE DONE IN 2.2163476943969727 SECONDS, reward -5.1577653884887695, action 3\n",
      "EPISODE DONE IN 4.41878342628479 SECONDS, reward -6.241055011749268, action 4\n",
      "EPISODE DONE IN 6.534733057022095 SECONDS, reward -11.410346984863281, action 0\n",
      "EPISODE DONE IN 8.519166231155396 SECONDS, reward -10.700309753417969, action 0\n",
      "\n",
      "\n",
      "EPISODE: 25\n",
      "EPISODE DONE IN 1.907134771347046 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 3.559077739715576 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.218171119689941 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.876195669174194 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 1.9136812686920166 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.9066288471221924 SECONDS, reward -10.81537914276123, action 2\n",
      "EPISODE DONE IN 6.027541399002075 SECONDS, reward -11.397014617919922, action 3\n",
      "EPISODE DONE IN 8.23463773727417 SECONDS, reward -8.666144371032715, action 5\n",
      "\n",
      "\n",
      "EPISODE: 27\n",
      "EPISODE DONE IN 2.219909906387329 SECONDS, reward -4.735631942749023, action 1\n",
      "EPISODE DONE IN 4.428640842437744 SECONDS, reward -4.828263282775879, action 3\n",
      "EPISODE DONE IN 6.643805980682373 SECONDS, reward -4.974921226501465, action 4\n",
      "EPISODE DONE IN 8.850557327270508 SECONDS, reward -5.203013896942139, action 8\n",
      "\n",
      "\n",
      "EPISODE: 28\n",
      "EPISODE DONE IN 2.216522216796875 SECONDS, reward -4.942055702209473, action 3\n",
      "EPISODE DONE IN 4.426922559738159 SECONDS, reward -5.539551258087158, action 6\n",
      "EPISODE DONE IN 6.645169496536255 SECONDS, reward -5.539551258087158, action 4\n",
      "EPISODE DONE IN 8.765830516815186 SECONDS, reward -7.74782133102417, action 0\n",
      "\n",
      "\n",
      "EPISODE: 29\n",
      "EPISODE DONE IN 2.0315566062927246 SECONDS, reward -7.137362957000732, action 0\n",
      "EPISODE DONE IN 3.9355759620666504 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.839649438858032 SECONDS, reward -41.876434326171875, action 2\n",
      "EPISODE DONE IN 7.837998628616333 SECONDS, reward -2.2498552799224854, action 7\n",
      "\n",
      "\n",
      "EPISODE: 30\n",
      "EPISODE DONE IN 2.121650457382202 SECONDS, reward -6.668159008026123, action 3\n",
      "EPISODE DONE IN 4.328609943389893 SECONDS, reward -5.685062885284424, action 3\n",
      "EPISODE DONE IN 6.5408525466918945 SECONDS, reward -7.202720642089844, action 1\n",
      "EPISODE DONE IN 8.65477204322815 SECONDS, reward -14.544827461242676, action 0\n",
      "\n",
      "\n",
      "EPISODE: 31\n",
      "EPISODE DONE IN 2.1202163696289062 SECONDS, reward -13.430496215820312, action 8\n",
      "EPISODE DONE IN 4.231895208358765 SECONDS, reward -13.61063003540039, action 5\n",
      "EPISODE DONE IN 6.376543998718262 SECONDS, reward -13.61063003540039, action 1\n",
      "EPISODE DONE IN 8.591092586517334 SECONDS, reward -14.604082107543945, action 8\n",
      "\n",
      "\n",
      "EPISODE: 32\n",
      "EPISODE DONE IN 2.1276609897613525 SECONDS, reward -3.3291099071502686, action 0\n",
      "EPISODE DONE IN 4.247312068939209 SECONDS, reward -3.3389577865600586, action 1\n",
      "EPISODE DONE IN 6.380238771438599 SECONDS, reward -3.7189481258392334, action 6\n",
      "EPISODE DONE IN 8.501820087432861 SECONDS, reward -3.5043349266052246, action 3\n",
      "\n",
      "\n",
      "EPISODE: 33\n",
      "EPISODE DONE IN 2.212531805038452 SECONDS, reward -10.127141952514648, action 5\n",
      "EPISODE DONE IN 4.419285535812378 SECONDS, reward -7.806257247924805, action 8\n",
      "EPISODE DONE IN 6.632724285125732 SECONDS, reward -10.346899032592773, action 1\n",
      "EPISODE DONE IN 8.840426206588745 SECONDS, reward -10.675570487976074, action 6\n",
      "\n",
      "\n",
      "EPISODE: 34\n",
      "EPISODE DONE IN 2.2171177864074707 SECONDS, reward -12.102229118347168, action 6\n",
      "EPISODE DONE IN 4.424455404281616 SECONDS, reward -12.102229118347168, action 8\n",
      "EPISODE DONE IN 6.63726282119751 SECONDS, reward -9.370536804199219, action 6\n",
      "EPISODE DONE IN 8.84355878829956 SECONDS, reward -9.187137603759766, action 5\n",
      "\n",
      "\n",
      "EPISODE: 35\n",
      "EPISODE DONE IN 2.2155206203460693 SECONDS, reward -4.592261791229248, action 2\n",
      "EPISODE DONE IN 4.424107789993286 SECONDS, reward -4.427534580230713, action 7\n",
      "EPISODE DONE IN 6.647423505783081 SECONDS, reward -4.052681922912598, action 8\n",
      "EPISODE DONE IN 8.854716539382935 SECONDS, reward -6.608536720275879, action 1\n",
      "\n",
      "\n",
      "EPISODE: 36\n",
      "EPISODE DONE IN 2.217528820037842 SECONDS, reward -9.50339126586914, action 4\n",
      "EPISODE DONE IN 4.423780918121338 SECONDS, reward -9.421845436096191, action 8\n",
      "EPISODE DONE IN 6.638589859008789 SECONDS, reward -9.059988021850586, action 4\n",
      "EPISODE DONE IN 8.847018480300903 SECONDS, reward -6.399573802947998, action 3\n",
      "\n",
      "\n",
      "EPISODE: 37\n",
      "EPISODE DONE IN 2.2154297828674316 SECONDS, reward -4.482184886932373, action 2\n",
      "EPISODE DONE IN 4.330798864364624 SECONDS, reward -9.93135929107666, action 0\n",
      "EPISODE DONE IN 6.456383943557739 SECONDS, reward -13.110821723937988, action 2\n",
      "EPISODE DONE IN 8.475522518157959 SECONDS, reward -18.743179321289062, action 0\n",
      "\n",
      "\n",
      "EPISODE: 38\n",
      "EPISODE DONE IN 1.9077684879302979 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 3.8055286407470703 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.470901966094971 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.450773239135742 SECONDS, reward -7.8201141357421875, action 8\n",
      "\n",
      "\n",
      "EPISODE: 39\n",
      "EPISODE DONE IN 2.2327961921691895 SECONDS, reward -12.502445220947266, action 8\n",
      "EPISODE DONE IN 4.28299880027771 SECONDS, reward -12.502445220947266, action 0\n",
      "EPISODE DONE IN 6.318272590637207 SECONDS, reward -12.502445220947266, action 0\n",
      "EPISODE DONE IN 8.34126877784729 SECONDS, reward -12.84135913848877, action 7\n",
      "\n",
      "\n",
      "EPISODE: 40\n",
      "EPISODE DONE IN 2.037752151489258 SECONDS, reward -12.84135913848877, action 8\n",
      "EPISODE DONE IN 4.153419733047485 SECONDS, reward -12.723369598388672, action 3\n",
      "EPISODE DONE IN 6.391712188720703 SECONDS, reward -12.100295066833496, action 5\n",
      "EPISODE DONE IN 8.620956420898438 SECONDS, reward -13.988862037658691, action 1\n",
      "\n",
      "\n",
      "EPISODE: 41\n",
      "EPISODE DONE IN 2.4066357612609863 SECONDS, reward -4.5782999992370605, action 1\n",
      "EPISODE DONE IN 4.86023736000061 SECONDS, reward -4.483555793762207, action 1\n",
      "EPISODE DONE IN 7.395246267318726 SECONDS, reward -5.940282344818115, action 1\n",
      "EPISODE DONE IN 9.684347867965698 SECONDS, reward -4.247969150543213, action 3\n",
      "\n",
      "\n",
      "EPISODE: 42\n",
      "EPISODE DONE IN 2.306040048599243 SECONDS, reward -12.407477378845215, action 7\n",
      "EPISODE DONE IN 4.6109938621521 SECONDS, reward -13.086584091186523, action 6\n",
      "EPISODE DONE IN 6.874724388122559 SECONDS, reward -10.119953155517578, action 5\n",
      "EPISODE DONE IN 9.121480941772461 SECONDS, reward -13.337421417236328, action 1\n",
      "\n",
      "\n",
      "EPISODE: 43\n",
      "EPISODE DONE IN 2.1421360969543457 SECONDS, reward -5.938362121582031, action 0\n",
      "EPISODE DONE IN 4.271939516067505 SECONDS, reward -5.938362121582031, action 6\n",
      "EPISODE DONE IN 6.418838977813721 SECONDS, reward -7.515113353729248, action 4\n",
      "EPISODE DONE IN 8.560944080352783 SECONDS, reward -8.211641311645508, action 3\n",
      "\n",
      "\n",
      "EPISODE: 44\n",
      "EPISODE DONE IN 2.2398393154144287 SECONDS, reward -7.79461145401001, action 5\n",
      "EPISODE DONE IN 4.5247814655303955 SECONDS, reward -9.772894859313965, action 1\n",
      "EPISODE DONE IN 6.822493553161621 SECONDS, reward -9.563340187072754, action 1\n",
      "EPISODE DONE IN 9.238091945648193 SECONDS, reward -9.519966125488281, action 2\n",
      "\n",
      "\n",
      "EPISODE: 45\n",
      "EPISODE DONE IN 2.3159008026123047 SECONDS, reward -8.124649047851562, action 4\n",
      "EPISODE DONE IN 4.5871477127075195 SECONDS, reward -8.124649047851562, action 1\n",
      "EPISODE DONE IN 6.809757709503174 SECONDS, reward -8.821460723876953, action 7\n",
      "EPISODE DONE IN 9.020291566848755 SECONDS, reward -9.450146675109863, action 6\n",
      "\n",
      "\n",
      "EPISODE: 46\n",
      "EPISODE DONE IN 2.140425205230713 SECONDS, reward -3.7842025756835938, action 0\n",
      "EPISODE DONE IN 4.264090061187744 SECONDS, reward -3.9172821044921875, action 8\n",
      "EPISODE DONE IN 6.390499114990234 SECONDS, reward -5.237964630126953, action 6\n",
      "EPISODE DONE IN 8.482247114181519 SECONDS, reward -3.8031256198883057, action 0\n",
      "\n",
      "\n",
      "EPISODE: 47\n",
      "EPISODE DONE IN 2.140260696411133 SECONDS, reward -7.510513782501221, action 4\n",
      "EPISODE DONE IN 4.428531885147095 SECONDS, reward -7.510513782501221, action 8\n",
      "EPISODE DONE IN 6.441291093826294 SECONDS, reward -6.467592716217041, action 0\n",
      "EPISODE DONE IN 8.438612461090088 SECONDS, reward -6.467592716217041, action 0\n",
      "\n",
      "\n",
      "EPISODE: 48\n",
      "EPISODE DONE IN 1.9676177501678467 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 4.06660795211792 SECONDS, reward -85.42497253417969, action 1\n",
      "EPISODE DONE IN 6.136803388595581 SECONDS, reward -34.401145935058594, action 2\n",
      "EPISODE DONE IN 8.268158912658691 SECONDS, reward -6.942699909210205, action 4\n",
      "\n",
      "\n",
      "EPISODE: 49\n",
      "EPISODE DONE IN 2.264519691467285 SECONDS, reward -4.410433292388916, action 1\n",
      "EPISODE DONE IN 4.600745677947998 SECONDS, reward -4.53513240814209, action 3\n",
      "EPISODE DONE IN 6.870677709579468 SECONDS, reward -5.203013896942139, action 8\n",
      "EPISODE DONE IN 9.112971305847168 SECONDS, reward -4.949432373046875, action 2\n",
      "\n",
      "\n",
      "EPISODE: 50\n",
      "EPISODE DONE IN 2.2586450576782227 SECONDS, reward -10.024249076843262, action 6\n",
      "EPISODE DONE IN 4.6875245571136475 SECONDS, reward -9.882925033569336, action 4\n",
      "EPISODE DONE IN 6.9348464012146 SECONDS, reward -9.112987518310547, action 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 9.181569576263428 SECONDS, reward -11.470117568969727, action 1\n",
      "\n",
      "\n",
      "EPISODE: 51\n",
      "EPISODE DONE IN 2.2880303859710693 SECONDS, reward -12.889762878417969, action 7\n",
      "EPISODE DONE IN 4.524988412857056 SECONDS, reward -12.462027549743652, action 1\n",
      "EPISODE DONE IN 6.846118211746216 SECONDS, reward -12.356355667114258, action 2\n",
      "EPISODE DONE IN 9.093249797821045 SECONDS, reward -12.718636512756348, action 8\n",
      "\n",
      "\n",
      "EPISODE: 52\n",
      "EPISODE DONE IN 2.2452502250671387 SECONDS, reward -12.718636512756348, action 7\n",
      "EPISODE DONE IN 4.451068162918091 SECONDS, reward -11.20676326751709, action 3\n",
      "EPISODE DONE IN 6.660761833190918 SECONDS, reward -9.984431266784668, action 8\n",
      "EPISODE DONE IN 8.861959218978882 SECONDS, reward -9.984431266784668, action 8\n",
      "\n",
      "\n",
      "EPISODE: 53\n",
      "EPISODE DONE IN 2.2958922386169434 SECONDS, reward -8.599343299865723, action 6\n",
      "EPISODE DONE IN 4.4981606006622314 SECONDS, reward -8.964300155639648, action 6\n",
      "EPISODE DONE IN 6.710667371749878 SECONDS, reward -9.641918182373047, action 5\n",
      "EPISODE DONE IN 8.912553310394287 SECONDS, reward -9.407674789428711, action 5\n",
      "\n",
      "\n",
      "EPISODE: 54\n",
      "EPISODE DONE IN 2.123844623565674 SECONDS, reward -6.442177772521973, action 0\n",
      "EPISODE DONE IN 4.129227638244629 SECONDS, reward -5.130353927612305, action 0\n",
      "EPISODE DONE IN 6.146482944488525 SECONDS, reward -5.130353927612305, action 5\n",
      "EPISODE DONE IN 8.166085720062256 SECONDS, reward -3.5406901836395264, action 6\n",
      "\n",
      "\n",
      "EPISODE: 55\n",
      "EPISODE DONE IN 2.038466691970825 SECONDS, reward -3.5406901836395264, action 0\n",
      "EPISODE DONE IN 4.060094833374023 SECONDS, reward -3.5406901836395264, action 0\n",
      "EPISODE DONE IN 6.008566617965698 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 7.964034557342529 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 56\n",
      "EPISODE DONE IN 2.172928810119629 SECONDS, reward -16.002727508544922, action 2\n",
      "EPISODE DONE IN 4.44045352935791 SECONDS, reward -5.938267707824707, action 7\n",
      "EPISODE DONE IN 6.614874362945557 SECONDS, reward -5.938267707824707, action 0\n",
      "EPISODE DONE IN 8.733548641204834 SECONDS, reward -5.608471393585205, action 4\n",
      "\n",
      "\n",
      "EPISODE: 57\n",
      "EPISODE DONE IN 2.0308899879455566 SECONDS, reward -7.233112812042236, action 0\n",
      "EPISODE DONE IN 4.101092338562012 SECONDS, reward -10.247737884521484, action 3\n",
      "EPISODE DONE IN 6.3557093143463135 SECONDS, reward -7.666150093078613, action 3\n",
      "EPISODE DONE IN 8.511817455291748 SECONDS, reward -5.399789810180664, action 5\n",
      "\n",
      "\n",
      "EPISODE: 58\n",
      "EPISODE DONE IN 2.243764877319336 SECONDS, reward -4.374715805053711, action 2\n",
      "EPISODE DONE IN 4.457035064697266 SECONDS, reward -7.693740367889404, action 0\n",
      "EPISODE DONE IN 6.5392138957977295 SECONDS, reward -19.281328201293945, action 0\n",
      "EPISODE DONE IN 8.488298892974854 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 59\n",
      "EPISODE DONE IN 1.8052291870117188 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.8084888458251953 SECONDS, reward -41.929996490478516, action 2\n",
      "EPISODE DONE IN 5.912144184112549 SECONDS, reward -13.499977111816406, action 6\n",
      "EPISODE DONE IN 7.9777703285217285 SECONDS, reward -13.499977111816406, action 0\n",
      "\n",
      "\n",
      "EPISODE: 60\n",
      "EPISODE DONE IN 2.045166492462158 SECONDS, reward -13.499977111816406, action 0\n",
      "EPISODE DONE IN 4.209775447845459 SECONDS, reward -4.0137481689453125, action 6\n",
      "EPISODE DONE IN 6.2930333614349365 SECONDS, reward -10.47986888885498, action 3\n",
      "EPISODE DONE IN 8.419753074645996 SECONDS, reward -10.47986888885498, action 0\n",
      "\n",
      "\n",
      "EPISODE: 61\n",
      "EPISODE DONE IN 2.0909969806671143 SECONDS, reward -10.47986888885498, action 0\n",
      "EPISODE DONE IN 4.038615465164185 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.757999420166016 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.731478214263916 SECONDS, reward -19.538095474243164, action 4\n",
      "\n",
      "\n",
      "EPISODE: 62\n",
      "EPISODE DONE IN 2.115788221359253 SECONDS, reward -13.982704162597656, action 3\n",
      "EPISODE DONE IN 4.28612756729126 SECONDS, reward -14.343883514404297, action 1\n",
      "EPISODE DONE IN 6.472364902496338 SECONDS, reward -14.343883514404297, action 0\n",
      "EPISODE DONE IN 8.644214153289795 SECONDS, reward -14.713662147521973, action 6\n",
      "\n",
      "\n",
      "EPISODE: 63\n",
      "EPISODE DONE IN 2.2681729793548584 SECONDS, reward -14.713662147521973, action 3\n",
      "EPISODE DONE IN 4.3560357093811035 SECONDS, reward -14.204411506652832, action 0\n",
      "EPISODE DONE IN 6.5423431396484375 SECONDS, reward -6.93824577331543, action 7\n",
      "EPISODE DONE IN 8.791460990905762 SECONDS, reward -7.116986274719238, action 7\n",
      "\n",
      "\n",
      "EPISODE: 64\n",
      "EPISODE DONE IN 2.212002754211426 SECONDS, reward -9.936058044433594, action 5\n",
      "EPISODE DONE IN 4.4685118198394775 SECONDS, reward -10.994919776916504, action 1\n",
      "EPISODE DONE IN 6.718425273895264 SECONDS, reward -10.818953514099121, action 6\n",
      "EPISODE DONE IN 9.60701847076416 SECONDS, reward -12.175127029418945, action 0\n",
      "\n",
      "\n",
      "EPISODE: 65\n",
      "EPISODE DONE IN 2.201899528503418 SECONDS, reward -12.347704887390137, action 6\n",
      "EPISODE DONE IN 4.273941516876221 SECONDS, reward -11.502433776855469, action 0\n",
      "EPISODE DONE IN 6.353726863861084 SECONDS, reward -14.610015869140625, action 4\n",
      "EPISODE DONE IN 8.417704820632935 SECONDS, reward -14.610015869140625, action 0\n",
      "\n",
      "\n",
      "EPISODE: 66\n",
      "EPISODE DONE IN 2.0625734329223633 SECONDS, reward -15.955238342285156, action 7\n",
      "EPISODE DONE IN 4.226365089416504 SECONDS, reward -11.769864082336426, action 4\n",
      "EPISODE DONE IN 6.469352722167969 SECONDS, reward -11.901413917541504, action 5\n",
      "EPISODE DONE IN 8.801300764083862 SECONDS, reward -10.909695625305176, action 7\n",
      "\n",
      "\n",
      "EPISODE: 67\n",
      "EPISODE DONE IN 2.35406231880188 SECONDS, reward -5.112579822540283, action 3\n",
      "EPISODE DONE IN 4.469902515411377 SECONDS, reward -6.777515888214111, action 0\n",
      "EPISODE DONE IN 6.542598485946655 SECONDS, reward -14.352012634277344, action 0\n",
      "EPISODE DONE IN 8.595944166183472 SECONDS, reward -14.352012634277344, action 7\n",
      "\n",
      "\n",
      "EPISODE: 68\n",
      "EPISODE DONE IN 2.094024658203125 SECONDS, reward -11.742783546447754, action 1\n",
      "EPISODE DONE IN 4.256136178970337 SECONDS, reward -5.040409088134766, action 8\n",
      "EPISODE DONE IN 6.519745349884033 SECONDS, reward -5.771966934204102, action 4\n",
      "EPISODE DONE IN 8.763899087905884 SECONDS, reward -5.375536918640137, action 5\n",
      "\n",
      "\n",
      "EPISODE: 69\n",
      "EPISODE DONE IN 2.2847118377685547 SECONDS, reward -6.774402141571045, action 4\n",
      "EPISODE DONE IN 4.534909725189209 SECONDS, reward -7.286523342132568, action 6\n",
      "EPISODE DONE IN 6.85789942741394 SECONDS, reward -7.2122697830200195, action 6\n",
      "EPISODE DONE IN 8.977557897567749 SECONDS, reward -9.49067211151123, action 0\n",
      "\n",
      "\n",
      "EPISODE: 70\n",
      "EPISODE DONE IN 2.281792640686035 SECONDS, reward -12.668643951416016, action 8\n",
      "EPISODE DONE IN 4.306300401687622 SECONDS, reward -13.78392219543457, action 0\n",
      "EPISODE DONE IN 6.336740255355835 SECONDS, reward -15.213788986206055, action 5\n",
      "EPISODE DONE IN 8.521291494369507 SECONDS, reward -15.522721290588379, action 1\n",
      "\n",
      "\n",
      "EPISODE: 71\n",
      "EPISODE DONE IN 2.1213977336883545 SECONDS, reward -15.522721290588379, action 8\n",
      "EPISODE DONE IN 4.308582544326782 SECONDS, reward -15.522721290588379, action 0\n",
      "EPISODE DONE IN 6.336351156234741 SECONDS, reward -18.748390197753906, action 0\n",
      "EPISODE DONE IN 8.241618871688843 SECONDS, reward -17.804615020751953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 72\n",
      "EPISODE DONE IN 1.9844930171966553 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.9881722927093506 SECONDS, reward -11.36351490020752, action 5\n",
      "EPISODE DONE IN 6.192621946334839 SECONDS, reward -11.682111740112305, action 1\n",
      "EPISODE DONE IN 8.403872013092041 SECONDS, reward -10.110922813415527, action 3\n",
      "\n",
      "\n",
      "EPISODE: 73\n",
      "EPISODE DONE IN 2.2373321056365967 SECONDS, reward -7.311703205108643, action 3\n",
      "EPISODE DONE IN 4.362778425216675 SECONDS, reward -14.143834114074707, action 0\n",
      "EPISODE DONE IN 6.489874839782715 SECONDS, reward -14.143834114074707, action 1\n",
      "EPISODE DONE IN 8.67504072189331 SECONDS, reward -10.768067359924316, action 4\n",
      "\n",
      "\n",
      "EPISODE: 74\n",
      "EPISODE DONE IN 2.130357027053833 SECONDS, reward -7.93746280670166, action 1\n",
      "EPISODE DONE IN 4.390129566192627 SECONDS, reward -4.416027069091797, action 3\n",
      "EPISODE DONE IN 6.891204595565796 SECONDS, reward -4.416027069091797, action 1\n",
      "EPISODE DONE IN 9.230137348175049 SECONDS, reward -4.5782999992370605, action 5\n",
      "\n",
      "\n",
      "EPISODE: 75\n",
      "EPISODE DONE IN 2.209339141845703 SECONDS, reward -11.39451789855957, action 6\n",
      "EPISODE DONE IN 4.423709869384766 SECONDS, reward -12.087119102478027, action 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 6.542005300521851 SECONDS, reward -11.01563835144043, action 0\n",
      "EPISODE DONE IN 8.655756950378418 SECONDS, reward -11.15576457977295, action 6\n",
      "\n",
      "\n",
      "EPISODE: 76\n",
      "EPISODE DONE IN 2.113567590713501 SECONDS, reward -9.718331336975098, action 5\n",
      "EPISODE DONE IN 4.134204626083374 SECONDS, reward -11.321500778198242, action 0\n",
      "EPISODE DONE IN 6.17864990234375 SECONDS, reward -11.321500778198242, action 0\n",
      "EPISODE DONE IN 8.27933931350708 SECONDS, reward -22.187671661376953, action 1\n",
      "\n",
      "\n",
      "EPISODE: 77\n",
      "EPISODE DONE IN 2.0618443489074707 SECONDS, reward -35.183109283447266, action 1\n",
      "EPISODE DONE IN 4.283813953399658 SECONDS, reward -17.68265724182129, action 2\n",
      "EPISODE DONE IN 6.6113550662994385 SECONDS, reward -5.299343585968018, action 2\n",
      "EPISODE DONE IN 8.864080905914307 SECONDS, reward -4.478099346160889, action 4\n",
      "\n",
      "\n",
      "EPISODE: 78\n",
      "EPISODE DONE IN 2.1659154891967773 SECONDS, reward -7.153262138366699, action 0\n",
      "EPISODE DONE IN 4.426259994506836 SECONDS, reward -7.836299896240234, action 6\n",
      "EPISODE DONE IN 6.612280607223511 SECONDS, reward -3.2858059406280518, action 7\n",
      "EPISODE DONE IN 8.891575336456299 SECONDS, reward -3.848159074783325, action 7\n",
      "\n",
      "\n",
      "EPISODE: 79\n",
      "EPISODE DONE IN 2.375520944595337 SECONDS, reward -10.831538200378418, action 7\n",
      "EPISODE DONE IN 4.652765512466431 SECONDS, reward -10.62860107421875, action 5\n",
      "EPISODE DONE IN 6.948328495025635 SECONDS, reward -10.415144920349121, action 8\n",
      "EPISODE DONE IN 9.211983919143677 SECONDS, reward -12.45203971862793, action 0\n",
      "\n",
      "\n",
      "EPISODE: 80\n",
      "EPISODE DONE IN 2.2053005695343018 SECONDS, reward -5.229360103607178, action 0\n",
      "EPISODE DONE IN 4.1145124435424805 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 6.083439826965332 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 8.259596109390259 SECONDS, reward -1.9823713302612305, action 8\n",
      "\n",
      "\n",
      "EPISODE: 81\n",
      "EPISODE DONE IN 2.0869522094726562 SECONDS, reward -1.9823713302612305, action 0\n",
      "EPISODE DONE IN 4.200850963592529 SECONDS, reward -1.9823713302612305, action 0\n",
      "EPISODE DONE IN 6.361215353012085 SECONDS, reward -1.468550443649292, action 4\n",
      "EPISODE DONE IN 8.403778791427612 SECONDS, reward -3.396500587463379, action 6\n",
      "\n",
      "\n",
      "EPISODE: 82\n",
      "EPISODE DONE IN 2.036564826965332 SECONDS, reward -3.396500587463379, action 0\n",
      "EPISODE DONE IN 4.175367832183838 SECONDS, reward -4.204638481140137, action 4\n",
      "EPISODE DONE IN 6.423262119293213 SECONDS, reward -3.3670830726623535, action 7\n",
      "EPISODE DONE IN 8.594896793365479 SECONDS, reward -3.031968355178833, action 4\n",
      "\n",
      "\n",
      "EPISODE: 83\n",
      "EPISODE DONE IN 2.33072829246521 SECONDS, reward -3.031968355178833, action 0\n",
      "EPISODE DONE IN 4.336800575256348 SECONDS, reward -2.2979936599731445, action 0\n",
      "EPISODE DONE IN 6.365105152130127 SECONDS, reward -6.956314563751221, action 3\n",
      "EPISODE DONE IN 8.286897659301758 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 84\n",
      "EPISODE DONE IN 1.927551507949829 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.837582588195801 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.776492357254028 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 7.770118236541748 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 85\n",
      "EPISODE DONE IN 1.9932312965393066 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 4.003145933151245 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 6.053858757019043 SECONDS, reward -85.31786346435547, action 1\n",
      "EPISODE DONE IN 8.230998754501343 SECONDS, reward -2.6712796688079834, action 7\n",
      "\n",
      "\n",
      "EPISODE: 86\n",
      "EPISODE DONE IN 2.12554669380188 SECONDS, reward -2.6712796688079834, action 0\n",
      "EPISODE DONE IN 4.376978158950806 SECONDS, reward -3.669752359390259, action 4\n",
      "EPISODE DONE IN 6.486755132675171 SECONDS, reward -7.224511623382568, action 0\n",
      "EPISODE DONE IN 8.6077880859375 SECONDS, reward -16.622072219848633, action 2\n",
      "\n",
      "\n",
      "EPISODE: 87\n",
      "EPISODE DONE IN 2.1555418968200684 SECONDS, reward -11.201549530029297, action 3\n",
      "EPISODE DONE IN 4.189033508300781 SECONDS, reward -20.140548706054688, action 0\n",
      "EPISODE DONE IN 6.21843695640564 SECONDS, reward -20.140548706054688, action 0\n",
      "EPISODE DONE IN 8.19408392906189 SECONDS, reward -30.819826126098633, action 0\n",
      "\n",
      "\n",
      "EPISODE: 88\n",
      "EPISODE DONE IN 2.1026692390441895 SECONDS, reward -19.29058074951172, action 6\n",
      "EPISODE DONE IN 4.336089849472046 SECONDS, reward -11.025607109069824, action 5\n",
      "EPISODE DONE IN 6.554481267929077 SECONDS, reward -11.9015531539917, action 4\n",
      "EPISODE DONE IN 8.828781127929688 SECONDS, reward -11.9015531539917, action 0\n",
      "\n",
      "\n",
      "EPISODE: 89\n",
      "EPISODE DONE IN 2.225609540939331 SECONDS, reward -12.332873344421387, action 5\n",
      "EPISODE DONE IN 4.409241199493408 SECONDS, reward -9.445296287536621, action 7\n",
      "EPISODE DONE IN 6.481926441192627 SECONDS, reward -8.65379524230957, action 0\n",
      "EPISODE DONE IN 8.475127696990967 SECONDS, reward -8.65379524230957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 90\n",
      "EPISODE DONE IN 1.9993464946746826 SECONDS, reward -11.796281814575195, action 8\n",
      "EPISODE DONE IN 3.9887492656707764 SECONDS, reward -11.513713836669922, action 3\n",
      "EPISODE DONE IN 6.11238169670105 SECONDS, reward -11.983352661132812, action 2\n",
      "EPISODE DONE IN 8.325205087661743 SECONDS, reward -11.102688789367676, action 2\n",
      "\n",
      "\n",
      "EPISODE: 91\n",
      "EPISODE DONE IN 2.1290624141693115 SECONDS, reward -17.797245025634766, action 0\n",
      "EPISODE DONE IN 4.133385181427002 SECONDS, reward -16.841455459594727, action 0\n",
      "EPISODE DONE IN 6.13773512840271 SECONDS, reward -6.71436882019043, action 4\n",
      "EPISODE DONE IN 8.04230284690857 SECONDS, reward -19.538095474243164, action 0\n",
      "\n",
      "\n",
      "EPISODE: 92\n",
      "EPISODE DONE IN 1.9174470901489258 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 4.02297043800354 SECONDS, reward -7.137362957000732, action 6\n",
      "EPISODE DONE IN 6.055752277374268 SECONDS, reward -5.086813926696777, action 5\n",
      "EPISODE DONE IN 8.08538293838501 SECONDS, reward -5.086813926696777, action 0\n",
      "\n",
      "\n",
      "EPISODE: 93\n",
      "EPISODE DONE IN 2.0349838733673096 SECONDS, reward -5.086813926696777, action 0\n",
      "EPISODE DONE IN 4.0625786781311035 SECONDS, reward -10.34347915649414, action 3\n",
      "EPISODE DONE IN 6.093377113342285 SECONDS, reward -10.247737884521484, action 4\n",
      "EPISODE DONE IN 8.224508047103882 SECONDS, reward -2.8868651390075684, action 7\n",
      "\n",
      "\n",
      "EPISODE: 94\n",
      "EPISODE DONE IN 2.2160253524780273 SECONDS, reward -8.042205810546875, action 5\n",
      "EPISODE DONE IN 4.427638053894043 SECONDS, reward -8.168535232543945, action 8\n",
      "EPISODE DONE IN 6.647783517837524 SECONDS, reward -8.089200973510742, action 8\n",
      "EPISODE DONE IN 8.76646900177002 SECONDS, reward -9.010717391967773, action 0\n",
      "\n",
      "\n",
      "EPISODE: 95\n",
      "EPISODE DONE IN 2.1260714530944824 SECONDS, reward -5.623568534851074, action 2\n",
      "EPISODE DONE IN 4.245413303375244 SECONDS, reward -7.084532737731934, action 6\n",
      "EPISODE DONE IN 6.3679187297821045 SECONDS, reward -6.9173264503479, action 7\n",
      "EPISODE DONE IN 8.57965087890625 SECONDS, reward -6.350681781768799, action 1\n",
      "\n",
      "\n",
      "EPISODE: 96\n",
      "EPISODE DONE IN 2.216555118560791 SECONDS, reward -9.23043155670166, action 4\n",
      "EPISODE DONE IN 4.429358959197998 SECONDS, reward -9.038897514343262, action 5\n",
      "EPISODE DONE IN 6.552857875823975 SECONDS, reward -10.212416648864746, action 0\n",
      "EPISODE DONE IN 8.676458358764648 SECONDS, reward -11.296485900878906, action 7\n",
      "\n",
      "\n",
      "EPISODE: 97\n",
      "EPISODE DONE IN 2.123304843902588 SECONDS, reward -9.748747825622559, action 3\n",
      "EPISODE DONE IN 4.147001504898071 SECONDS, reward -14.352012634277344, action 0\n",
      "EPISODE DONE IN 6.275379419326782 SECONDS, reward -6.777515888214111, action 5\n",
      "EPISODE DONE IN 8.400784730911255 SECONDS, reward -8.891901016235352, action 2\n",
      "\n",
      "\n",
      "EPISODE: 98\n",
      "EPISODE DONE IN 2.1248111724853516 SECONDS, reward -8.891901016235352, action 3\n",
      "EPISODE DONE IN 4.250435829162598 SECONDS, reward -8.891901016235352, action 0\n",
      "EPISODE DONE IN 6.45482063293457 SECONDS, reward -7.434122085571289, action 6\n",
      "EPISODE DONE IN 8.654152393341064 SECONDS, reward -6.93824577331543, action 7\n",
      "\n",
      "\n",
      "EPISODE: 99\n",
      "EPISODE DONE IN 2.126422166824341 SECONDS, reward -5.503486633300781, action 2\n",
      "EPISODE DONE IN 4.350275039672852 SECONDS, reward -4.170548915863037, action 8\n",
      "EPISODE DONE IN 6.4809792041778564 SECONDS, reward -5.483856678009033, action 0\n",
      "EPISODE DONE IN 8.478262901306152 SECONDS, reward -4.207798004150391, action 0\n",
      "\n",
      "\n",
      "EPISODE: 100\n",
      "EPISODE DONE IN 2.0925486087799072 SECONDS, reward -11.97093677520752, action 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 4.005749702453613 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 6.033859968185425 SECONDS, reward -19.834184646606445, action 3\n",
      "EPISODE DONE IN 8.052744388580322 SECONDS, reward -19.834184646606445, action 0\n",
      "\n",
      "\n",
      "EPISODE: 101\n",
      "EPISODE DONE IN 2.031019687652588 SECONDS, reward -29.764801025390625, action 1\n",
      "EPISODE DONE IN 4.069420099258423 SECONDS, reward -29.764801025390625, action 0\n",
      "EPISODE DONE IN 5.983039140701294 SECONDS, reward -86.46080780029297, action 0\n",
      "EPISODE DONE IN 7.88378381729126 SECONDS, reward -86.46080780029297, action 0\n",
      "\n",
      "\n",
      "EPISODE: 102\n",
      "EPISODE DONE IN 1.9044981002807617 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.810676097869873 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.717270374298096 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 7.730165004730225 SECONDS, reward -13.28564453125, action 4\n",
      "\n",
      "\n",
      "EPISODE: 103\n",
      "EPISODE DONE IN 2.0176239013671875 SECONDS, reward -15.955238342285156, action 7\n",
      "EPISODE DONE IN 4.033334255218506 SECONDS, reward -15.955238342285156, action 0\n",
      "EPISODE DONE IN 6.052196264266968 SECONDS, reward -15.955238342285156, action 0\n",
      "EPISODE DONE IN 7.949065685272217 SECONDS, reward -18.279748916625977, action 0\n",
      "\n",
      "\n",
      "EPISODE: 104\n",
      "EPISODE DONE IN 1.8978445529937744 SECONDS, reward -86.46080780029297, action 1\n",
      "EPISODE DONE IN 3.79899525642395 SECONDS, reward -86.46080780029297, action 0\n",
      "EPISODE DONE IN 5.819487571716309 SECONDS, reward -10.013976097106934, action 8\n",
      "EPISODE DONE IN 7.835811376571655 SECONDS, reward -10.013976097106934, action 0\n",
      "\n",
      "\n",
      "EPISODE: 105\n",
      "EPISODE DONE IN 2.0193607807159424 SECONDS, reward -11.471070289611816, action 5\n",
      "EPISODE DONE IN 4.1267876625061035 SECONDS, reward -9.010717391967773, action 8\n",
      "EPISODE DONE IN 6.238033294677734 SECONDS, reward -8.38641357421875, action 3\n",
      "EPISODE DONE IN 8.443721771240234 SECONDS, reward -8.132691383361816, action 8\n",
      "\n",
      "\n",
      "EPISODE: 106\n",
      "EPISODE DONE IN 2.1199493408203125 SECONDS, reward -2.8611133098602295, action 0\n",
      "EPISODE DONE IN 4.12112832069397 SECONDS, reward -1.524810791015625, action 0\n",
      "EPISODE DONE IN 6.0172929763793945 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 7.911285877227783 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 107\n",
      "EPISODE DONE IN 2.0220377445220947 SECONDS, reward -13.617352485656738, action 2\n",
      "EPISODE DONE IN 4.037165880203247 SECONDS, reward -13.617352485656738, action 0\n",
      "EPISODE DONE IN 6.054642677307129 SECONDS, reward -13.617352485656738, action 0\n",
      "EPISODE DONE IN 8.066319942474365 SECONDS, reward -36.82756805419922, action 1\n",
      "\n",
      "\n",
      "EPISODE: 108\n",
      "EPISODE DONE IN 1.8968112468719482 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.918208122253418 SECONDS, reward -34.431583404541016, action 2\n",
      "EPISODE DONE IN 5.941495180130005 SECONDS, reward -34.431583404541016, action 0\n",
      "EPISODE DONE IN 7.964778900146484 SECONDS, reward -16.280006408691406, action 2\n",
      "\n",
      "\n",
      "EPISODE: 109\n",
      "EPISODE DONE IN 2.026257276535034 SECONDS, reward -16.280006408691406, action 0\n",
      "EPISODE DONE IN 4.049899578094482 SECONDS, reward -16.819149017333984, action 5\n",
      "EPISODE DONE IN 6.073994874954224 SECONDS, reward -16.819149017333984, action 0\n",
      "EPISODE DONE IN 8.09416675567627 SECONDS, reward -7.062016487121582, action 4\n",
      "\n",
      "\n",
      "EPISODE: 110\n",
      "EPISODE DONE IN 2.1125619411468506 SECONDS, reward -11.9015531539917, action 6\n",
      "EPISODE DONE IN 4.220765113830566 SECONDS, reward -11.9015531539917, action 5\n",
      "EPISODE DONE IN 6.428637981414795 SECONDS, reward -9.463547706604004, action 5\n",
      "EPISODE DONE IN 8.629058599472046 SECONDS, reward -9.709413528442383, action 5\n",
      "\n",
      "\n",
      "EPISODE: 111\n",
      "EPISODE DONE IN 2.1202197074890137 SECONDS, reward -6.276932716369629, action 0\n",
      "EPISODE DONE IN 4.1178178787231445 SECONDS, reward -5.130353927612305, action 0\n",
      "EPISODE DONE IN 6.018053293228149 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.668905973434448 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 112\n",
      "EPISODE DONE IN 1.8984699249267578 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.790797710418701 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.6938371658325195 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 7.706521987915039 SECONDS, reward -13.28564453125, action 4\n",
      "\n",
      "\n",
      "EPISODE: 113\n",
      "EPISODE DONE IN 2.0218682289123535 SECONDS, reward -17.31688690185547, action 8\n",
      "EPISODE DONE IN 4.03839373588562 SECONDS, reward -17.31688690185547, action 0\n",
      "EPISODE DONE IN 6.056997776031494 SECONDS, reward -17.31688690185547, action 0\n",
      "EPISODE DONE IN 8.068927526473999 SECONDS, reward -19.834184646606445, action 3\n",
      "\n",
      "\n",
      "EPISODE: 114\n",
      "EPISODE DONE IN 2.016193389892578 SECONDS, reward -16.56825065612793, action 5\n",
      "EPISODE DONE IN 4.122791290283203 SECONDS, reward -11.449684143066406, action 1\n",
      "EPISODE DONE IN 6.23583459854126 SECONDS, reward -11.449684143066406, action 0\n",
      "EPISODE DONE IN 8.220653533935547 SECONDS, reward -10.696940422058105, action 0\n",
      "\n",
      "\n",
      "EPISODE: 115\n",
      "EPISODE DONE IN 1.9958524703979492 SECONDS, reward -12.117162704467773, action 8\n",
      "EPISODE DONE IN 3.894974708557129 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 5.802666664123535 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 7.827619552612305 SECONDS, reward -13.78392219543457, action 6\n",
      "\n",
      "\n",
      "EPISODE: 116\n",
      "EPISODE DONE IN 1.902451992034912 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.8066179752349854 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.78745174407959 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 7.703244209289551 SECONDS, reward -14.926665306091309, action 5\n",
      "\n",
      "\n",
      "EPISODE: 117\n",
      "EPISODE DONE IN 2.0174057483673096 SECONDS, reward -12.043066024780273, action 4\n",
      "EPISODE DONE IN 4.128483057022095 SECONDS, reward -12.312125205993652, action 1\n",
      "EPISODE DONE IN 6.2414257526397705 SECONDS, reward -12.312125205993652, action 0\n",
      "EPISODE DONE IN 8.226803302764893 SECONDS, reward -11.504106521606445, action 0\n",
      "\n",
      "\n",
      "EPISODE: 118\n",
      "EPISODE DONE IN 1.9913969039916992 SECONDS, reward -10.868637084960938, action 6\n",
      "EPISODE DONE IN 3.984994649887085 SECONDS, reward -9.153453826904297, action 8\n",
      "EPISODE DONE IN 6.101048231124878 SECONDS, reward -10.409063339233398, action 8\n",
      "EPISODE DONE IN 8.228453159332275 SECONDS, reward -10.409063339233398, action 0\n",
      "\n",
      "\n",
      "EPISODE: 119\n",
      "EPISODE DONE IN 2.1139655113220215 SECONDS, reward -11.827522277832031, action 7\n",
      "EPISODE DONE IN 4.1315391063690186 SECONDS, reward -11.591934204101562, action 0\n",
      "EPISODE DONE IN 6.041443109512329 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 8.06075406074524 SECONDS, reward -12.469583511352539, action 6\n",
      "\n",
      "\n",
      "EPISODE: 120\n",
      "EPISODE DONE IN 1.911611795425415 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.93520450592041 SECONDS, reward -10.469008445739746, action 3\n",
      "EPISODE DONE IN 5.965692758560181 SECONDS, reward -10.469008445739746, action 0\n",
      "EPISODE DONE IN 7.99049973487854 SECONDS, reward -9.846990585327148, action 8\n",
      "\n",
      "\n",
      "EPISODE: 121\n",
      "EPISODE DONE IN 2.119680404663086 SECONDS, reward -13.51629638671875, action 4\n",
      "EPISODE DONE IN 4.237783432006836 SECONDS, reward -7.762315273284912, action 8\n",
      "EPISODE DONE IN 6.35168981552124 SECONDS, reward -7.762315273284912, action 0\n",
      "EPISODE DONE IN 8.466259717941284 SECONDS, reward -7.639622211456299, action 7\n",
      "\n",
      "\n",
      "EPISODE: 122\n",
      "EPISODE DONE IN 2.0273962020874023 SECONDS, reward -2.851386308670044, action 0\n",
      "EPISODE DONE IN 4.0522215366363525 SECONDS, reward -3.1596837043762207, action 7\n",
      "EPISODE DONE IN 6.17474627494812 SECONDS, reward -3.9879746437072754, action 7\n",
      "EPISODE DONE IN 8.293111085891724 SECONDS, reward -3.5956265926361084, action 5\n",
      "\n",
      "\n",
      "EPISODE: 123\n",
      "EPISODE DONE IN 2.1226115226745605 SECONDS, reward -3.5956265926361084, action 0\n",
      "EPISODE DONE IN 4.114243507385254 SECONDS, reward -2.4051573276519775, action 0\n",
      "EPISODE DONE IN 6.014524698257446 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.91409158706665 SECONDS, reward -7.8201141357421875, action 8\n",
      "\n",
      "\n",
      "EPISODE: 124\n",
      "EPISODE DONE IN 2.0203258991241455 SECONDS, reward -11.471070289611816, action 5\n",
      "EPISODE DONE IN 4.045949697494507 SECONDS, reward -11.471070289611816, action 0\n",
      "EPISODE DONE IN 6.163178443908691 SECONDS, reward -9.58204174041748, action 1\n",
      "EPISODE DONE IN 8.174894094467163 SECONDS, reward -22.187671661376953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 2.0169456005096436 SECONDS, reward -36.82756805419922, action 2\n",
      "EPISODE DONE IN 4.126631498336792 SECONDS, reward -18.909191131591797, action 1\n",
      "EPISODE DONE IN 6.120004177093506 SECONDS, reward -18.728635787963867, action 0\n",
      "EPISODE DONE IN 8.228705644607544 SECONDS, reward -14.267126083374023, action 7\n",
      "\n",
      "\n",
      "EPISODE: 126\n",
      "EPISODE DONE IN 2.0311968326568604 SECONDS, reward -10.49156665802002, action 0\n",
      "EPISODE DONE IN 3.9268765449523926 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.927217721939087 SECONDS, reward -2.6712796688079834, action 1\n",
      "EPISODE DONE IN 7.921852350234985 SECONDS, reward -9.861931800842285, action 3\n",
      "\n",
      "\n",
      "EPISODE: 127\n",
      "EPISODE DONE IN 1.9969685077667236 SECONDS, reward -9.861931800842285, action 0\n",
      "EPISODE DONE IN 4.003129243850708 SECONDS, reward -9.861931800842285, action 0\n",
      "EPISODE DONE IN 6.002640008926392 SECONDS, reward -1.524810791015625, action 8\n",
      "EPISODE DONE IN 7.993456840515137 SECONDS, reward -1.7058779001235962, action 2\n",
      "\n",
      "\n",
      "EPISODE: 128\n",
      "EPISODE DONE IN 2.1171178817749023 SECONDS, reward -13.114609718322754, action 8\n",
      "EPISODE DONE IN 4.227041721343994 SECONDS, reward -13.114609718322754, action 0\n",
      "EPISODE DONE IN 6.359394550323486 SECONDS, reward -14.571922302246094, action 6\n",
      "EPISODE DONE IN 8.376548767089844 SECONDS, reward -13.78392219543457, action 0\n",
      "\n",
      "\n",
      "EPISODE: 129\n",
      "EPISODE DONE IN 2.017526626586914 SECONDS, reward -14.029321670532227, action 1\n",
      "EPISODE DONE IN 4.03305459022522 SECONDS, reward -14.029321670532227, action 0\n",
      "EPISODE DONE IN 5.928051948547363 SECONDS, reward -86.46080780029297, action 0\n",
      "EPISODE DONE IN 7.9450318813323975 SECONDS, reward -14.029321670532227, action 6\n",
      "\n",
      "\n",
      "EPISODE: 130\n",
      "EPISODE DONE IN 1.8954095840454102 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.9141578674316406 SECONDS, reward -3.8031256198883057, action 8\n",
      "EPISODE DONE IN 5.950991630554199 SECONDS, reward -3.8031256198883057, action 0\n",
      "EPISODE DONE IN 7.851947784423828 SECONDS, reward -7.835620880126953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 131\n",
      "EPISODE DONE IN 1.9973125457763672 SECONDS, reward -6.467592716217041, action 4\n",
      "EPISODE DONE IN 3.920581102371216 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 5.836368799209595 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 7.858264923095703 SECONDS, reward -25.68418312072754, action 1\n",
      "\n",
      "\n",
      "EPISODE: 132\n",
      "EPISODE DONE IN 2.0239028930664062 SECONDS, reward -25.68418312072754, action 4\n",
      "EPISODE DONE IN 4.140157461166382 SECONDS, reward -8.525846481323242, action 8\n",
      "EPISODE DONE IN 6.354546785354614 SECONDS, reward -8.954024314880371, action 3\n",
      "EPISODE DONE IN 8.564558744430542 SECONDS, reward -7.158180236816406, action 8\n",
      "\n",
      "\n",
      "EPISODE: 133\n",
      "EPISODE DONE IN 2.21747088432312 SECONDS, reward -8.132691383361816, action 5\n",
      "EPISODE DONE IN 4.423965215682983 SECONDS, reward -10.239689826965332, action 1\n",
      "EPISODE DONE IN 6.546164512634277 SECONDS, reward -11.779088020324707, action 0\n",
      "EPISODE DONE IN 8.542118549346924 SECONDS, reward -10.696940422058105, action 0\n",
      "\n",
      "\n",
      "EPISODE: 134\n",
      "EPISODE DONE IN 1.921046495437622 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 3.825242519378662 SECONDS, reward -14.94920539855957, action 5\n",
      "EPISODE DONE IN 5.735771417617798 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 7.7670488357543945 SECONDS, reward -5.150374412536621, action 7\n",
      "\n",
      "\n",
      "EPISODE: 135\n",
      "EPISODE DONE IN 2.0365676879882812 SECONDS, reward -5.150374412536621, action 0\n",
      "EPISODE DONE IN 4.063390016555786 SECONDS, reward -5.150374412536621, action 5\n",
      "EPISODE DONE IN 6.195540904998779 SECONDS, reward -3.700392961502075, action 7\n",
      "EPISODE DONE IN 8.215608358383179 SECONDS, reward -5.150374412536621, action 0\n",
      "\n",
      "\n",
      "EPISODE: 136\n",
      "EPISODE DONE IN 2.0365185737609863 SECONDS, reward -5.150374412536621, action 0\n",
      "EPISODE DONE IN 3.9391751289367676 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.608741283416748 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.5709779262542725 SECONDS, reward -27.10552215576172, action 3\n",
      "\n",
      "\n",
      "EPISODE: 137\n",
      "EPISODE DONE IN 2.0398616790771484 SECONDS, reward -18.905628204345703, action 2\n",
      "EPISODE DONE IN 4.146809816360474 SECONDS, reward -18.905628204345703, action 0\n",
      "EPISODE DONE IN 6.181910991668701 SECONDS, reward -18.905628204345703, action 0\n",
      "EPISODE DONE IN 8.086395978927612 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 138\n",
      "EPISODE DONE IN 1.6673204898834229 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5682733058929443 SECONDS, reward -19.564889907836914, action 4\n",
      "EPISODE DONE IN 5.602060317993164 SECONDS, reward -7.336960792541504, action 8\n",
      "EPISODE DONE IN 7.728303909301758 SECONDS, reward -2.2247960567474365, action 4\n",
      "\n",
      "\n",
      "EPISODE: 139\n",
      "EPISODE DONE IN 2.1300435066223145 SECONDS, reward -2.2247960567474365, action 0\n",
      "EPISODE DONE IN 4.128638744354248 SECONDS, reward -1.468550443649292, action 0\n",
      "EPISODE DONE IN 6.1299989223480225 SECONDS, reward -1.468550443649292, action 8\n",
      "EPISODE DONE IN 8.127982139587402 SECONDS, reward -1.6546659469604492, action 6\n",
      "\n",
      "\n",
      "EPISODE: 140\n",
      "EPISODE DONE IN 2.0015759468078613 SECONDS, reward -1.6546659469604492, action 0\n",
      "EPISODE DONE IN 4.127011060714722 SECONDS, reward -2.414292335510254, action 4\n",
      "EPISODE DONE IN 6.346574544906616 SECONDS, reward -4.4254469871521, action 1\n",
      "EPISODE DONE IN 8.394702672958374 SECONDS, reward -20.73712730407715, action 0\n",
      "\n",
      "\n",
      "EPISODE: 141\n",
      "EPISODE DONE IN 2.119823932647705 SECONDS, reward -10.96536922454834, action 3\n",
      "EPISODE DONE IN 4.2366883754730225 SECONDS, reward -8.745368003845215, action 5\n",
      "EPISODE DONE IN 6.35766077041626 SECONDS, reward -9.748747825622559, action 7\n",
      "EPISODE DONE IN 8.48067855834961 SECONDS, reward -9.748747825622559, action 0\n",
      "\n",
      "\n",
      "EPISODE: 142\n",
      "EPISODE DONE IN 2.0320160388946533 SECONDS, reward -5.150374412536621, action 0\n",
      "EPISODE DONE IN 4.080657720565796 SECONDS, reward -3.1596837043762207, action 7\n",
      "EPISODE DONE IN 5.988670349121094 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 8.018452644348145 SECONDS, reward -3.738368272781372, action 6\n",
      "\n",
      "\n",
      "EPISODE: 143\n",
      "EPISODE DONE IN 2.036736488342285 SECONDS, reward -3.738368272781372, action 0\n",
      "EPISODE DONE IN 3.9453701972961426 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.851502418518066 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 7.75121808052063 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 144\n",
      "EPISODE DONE IN 1.915724754333496 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.952172040939331 SECONDS, reward -34.00605392456055, action 1\n",
      "EPISODE DONE IN 6.085089683532715 SECONDS, reward -6.713439464569092, action 4\n",
      "EPISODE DONE IN 8.116279125213623 SECONDS, reward -20.709917068481445, action 0\n",
      "\n",
      "\n",
      "EPISODE: 145\n",
      "EPISODE DONE IN 2.1220192909240723 SECONDS, reward -14.343883514404297, action 3\n",
      "EPISODE DONE IN 4.238436698913574 SECONDS, reward -9.312237739562988, action 5\n",
      "EPISODE DONE IN 6.240602970123291 SECONDS, reward -8.488519668579102, action 0\n",
      "EPISODE DONE IN 8.432341814041138 SECONDS, reward -9.879685401916504, action 8\n",
      "\n",
      "\n",
      "EPISODE: 146\n",
      "EPISODE DONE IN 2.2544198036193848 SECONDS, reward -8.328449249267578, action 2\n",
      "EPISODE DONE IN 4.322389602661133 SECONDS, reward -11.819981575012207, action 0\n",
      "EPISODE DONE IN 6.359023332595825 SECONDS, reward -11.819981575012207, action 0\n",
      "EPISODE DONE IN 8.276653289794922 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 147\n",
      "EPISODE DONE IN 1.673841953277588 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5716938972473145 SECONDS, reward -27.141239166259766, action 3\n",
      "EPISODE DONE IN 5.486366510391235 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 7.5178704261779785 SECONDS, reward -10.469008445739746, action 6\n",
      "\n",
      "\n",
      "EPISODE: 148\n",
      "EPISODE DONE IN 2.0308713912963867 SECONDS, reward -10.469008445739746, action 0\n",
      "EPISODE DONE IN 3.9322547912597656 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.83464241027832 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 7.72888445854187 SECONDS, reward -7.8201141357421875, action 8\n",
      "\n",
      "\n",
      "EPISODE: 149\n",
      "EPISODE DONE IN 2.0227832794189453 SECONDS, reward -11.471070289611816, action 5\n",
      "EPISODE DONE IN 4.039880752563477 SECONDS, reward -11.471070289611816, action 0\n",
      "EPISODE DONE IN 6.062545299530029 SECONDS, reward -11.471070289611816, action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 7.9684977531433105 SECONDS, reward -21.154136657714844, action 0\n",
      "\n",
      "\n",
      "EPISODE: 150\n",
      "EPISODE DONE IN 1.658006191253662 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3321926593780518 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.001868009567261 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.902730226516724 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 151\n",
      "EPISODE DONE IN 1.9086871147155762 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.9383838176727295 SECONDS, reward -10.469008445739746, action 3\n",
      "EPISODE DONE IN 5.978132724761963 SECONDS, reward -10.469008445739746, action 0\n",
      "EPISODE DONE IN 8.009796857833862 SECONDS, reward -10.167935371398926, action 3\n",
      "\n",
      "\n",
      "EPISODE: 152\n",
      "EPISODE DONE IN 2.125250816345215 SECONDS, reward -13.368659019470215, action 2\n",
      "EPISODE DONE IN 4.151149272918701 SECONDS, reward -18.905628204345703, action 0\n",
      "EPISODE DONE IN 6.275512218475342 SECONDS, reward -13.564762115478516, action 3\n",
      "EPISODE DONE IN 8.298214435577393 SECONDS, reward -18.905628204345703, action 0\n",
      "\n",
      "\n",
      "EPISODE: 153\n",
      "EPISODE DONE IN 1.907362461090088 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.937410831451416 SECONDS, reward -10.257720947265625, action 4\n",
      "EPISODE DONE IN 5.838537931442261 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 7.734461069107056 SECONDS, reward -19.564889907836914, action 0\n",
      "\n",
      "\n",
      "EPISODE: 154\n",
      "EPISODE DONE IN 1.9961433410644531 SECONDS, reward -10.881702423095703, action 6\n",
      "EPISODE DONE IN 3.894955635070801 SECONDS, reward -19.29058074951172, action 0\n",
      "EPISODE DONE IN 5.916824579238892 SECONDS, reward -11.502433776855469, action 6\n",
      "EPISODE DONE IN 7.934363842010498 SECONDS, reward -11.502433776855469, action 0\n",
      "\n",
      "\n",
      "EPISODE: 155\n",
      "EPISODE DONE IN 2.0229415893554688 SECONDS, reward -14.029321670532227, action 1\n",
      "EPISODE DONE IN 4.039581775665283 SECONDS, reward -14.029321670532227, action 0\n",
      "EPISODE DONE IN 6.05989408493042 SECONDS, reward -14.029321670532227, action 6\n",
      "EPISODE DONE IN 8.078224658966064 SECONDS, reward -14.029321670532227, action 0\n",
      "\n",
      "\n",
      "EPISODE: 156\n",
      "EPISODE DONE IN 2.0190653800964355 SECONDS, reward -13.78392219543457, action 8\n",
      "EPISODE DONE IN 4.12884259223938 SECONDS, reward -12.828817367553711, action 2\n",
      "EPISODE DONE IN 6.122685432434082 SECONDS, reward -11.69565200805664, action 0\n",
      "EPISODE DONE IN 8.236247539520264 SECONDS, reward -12.676887512207031, action 5\n",
      "\n",
      "\n",
      "EPISODE: 157\n",
      "EPISODE DONE IN 2.115858793258667 SECONDS, reward -12.659364700317383, action 4\n",
      "EPISODE DONE IN 4.22852087020874 SECONDS, reward -12.312125205993652, action 1\n",
      "EPISODE DONE IN 6.3460259437561035 SECONDS, reward -12.312125205993652, action 0\n",
      "EPISODE DONE IN 8.462920188903809 SECONDS, reward -11.694568634033203, action 1\n",
      "\n",
      "\n",
      "EPISODE: 158\n",
      "EPISODE DONE IN 2.1199119091033936 SECONDS, reward -18.909191131591797, action 2\n",
      "EPISODE DONE IN 4.2313127517700195 SECONDS, reward -5.87684440612793, action 8\n",
      "EPISODE DONE IN 6.352185487747192 SECONDS, reward -5.87684440612793, action 0\n",
      "EPISODE DONE IN 8.34046483039856 SECONDS, reward -4.207798004150391, action 0\n",
      "\n",
      "\n",
      "EPISODE: 159\n",
      "EPISODE DONE IN 1.99947190284729 SECONDS, reward -9.153453826904297, action 6\n",
      "EPISODE DONE IN 3.89481782913208 SECONDS, reward -19.29058074951172, action 0\n",
      "EPISODE DONE IN 5.796398878097534 SECONDS, reward -19.29058074951172, action 0\n",
      "EPISODE DONE IN 7.817860126495361 SECONDS, reward -14.610015869140625, action 4\n",
      "\n",
      "\n",
      "EPISODE: 160\n",
      "EPISODE DONE IN 2.0203537940979004 SECONDS, reward -13.28564453125, action 5\n",
      "EPISODE DONE IN 4.13692307472229 SECONDS, reward -11.800392150878906, action 3\n",
      "EPISODE DONE IN 6.25357985496521 SECONDS, reward -11.800392150878906, action 0\n",
      "EPISODE DONE IN 8.368298053741455 SECONDS, reward -11.44843864440918, action 2\n",
      "\n",
      "\n",
      "EPISODE: 161\n",
      "EPISODE DONE IN 2.0982279777526855 SECONDS, reward -16.44278907775879, action 0\n",
      "EPISODE DONE IN 4.240623474121094 SECONDS, reward -13.519627571105957, action 6\n",
      "EPISODE DONE IN 6.296577453613281 SECONDS, reward -13.519627571105957, action 0\n",
      "EPISODE DONE IN 8.328585863113403 SECONDS, reward -10.47986888885498, action 3\n",
      "\n",
      "\n",
      "EPISODE: 162\n",
      "EPISODE DONE IN 2.1383731365203857 SECONDS, reward -10.489477157592773, action 5\n",
      "EPISODE DONE IN 4.250154972076416 SECONDS, reward -12.141951560974121, action 5\n",
      "EPISODE DONE IN 6.475182294845581 SECONDS, reward -10.110922813415527, action 1\n",
      "EPISODE DONE IN 8.59025526046753 SECONDS, reward -11.682111740112305, action 0\n",
      "\n",
      "\n",
      "EPISODE: 163\n",
      "EPISODE DONE IN 2.121685743331909 SECONDS, reward -10.212416648864746, action 4\n",
      "EPISODE DONE IN 4.234327554702759 SECONDS, reward -10.212416648864746, action 5\n",
      "EPISODE DONE IN 6.245064735412598 SECONDS, reward -9.923580169677734, action 0\n",
      "EPISODE DONE IN 8.245609998703003 SECONDS, reward -9.923580169677734, action 0\n",
      "\n",
      "\n",
      "EPISODE: 164\n",
      "EPISODE DONE IN 1.90920090675354 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.818617343902588 SECONDS, reward -27.141239166259766, action 3\n",
      "EPISODE DONE IN 5.849287986755371 SECONDS, reward -10.247737884521484, action 4\n",
      "EPISODE DONE IN 7.875903367996216 SECONDS, reward -10.247737884521484, action 0\n",
      "\n",
      "\n",
      "EPISODE: 165\n",
      "EPISODE DONE IN 2.032771348953247 SECONDS, reward -10.247737884521484, action 0\n",
      "EPISODE DONE IN 4.0608508586883545 SECONDS, reward -10.247737884521484, action 3\n",
      "EPISODE DONE IN 5.966463088989258 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 7.871594667434692 SECONDS, reward -27.141239166259766, action 0\n",
      "\n",
      "\n",
      "EPISODE: 166\n",
      "EPISODE DONE IN 1.9038951396942139 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 3.5622169971466064 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.2670793533325195 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.958224534988403 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 167\n",
      "EPISODE DONE IN 1.6626465320587158 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5621490478515625 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.467519760131836 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.496488809585571 SECONDS, reward -13.519627571105957, action 2\n",
      "\n",
      "\n",
      "EPISODE: 168\n",
      "EPISODE DONE IN 2.033203363418579 SECONDS, reward -13.519627571105957, action 0\n",
      "EPISODE DONE IN 3.949566602706909 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.853439807891846 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 7.536988019943237 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 169\n",
      "EPISODE DONE IN 1.7145726680755615 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3792779445648193 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.042967796325684 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.70074200630188 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 170\n",
      "EPISODE DONE IN 1.90382981300354 SECONDS, reward -30.819826126098633, action 3\n",
      "EPISODE DONE IN 3.864927053451538 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 5.91197657585144 SECONDS, reward -13.982704162597656, action 4\n",
      "EPISODE DONE IN 7.935861825942993 SECONDS, reward -13.982704162597656, action 0\n",
      "\n",
      "\n",
      "EPISODE: 171\n",
      "EPISODE DONE IN 1.972154140472412 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 3.9517743587493896 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.937574863433838 SECONDS, reward -14.926665306091309, action 5\n",
      "EPISODE DONE IN 8.018515825271606 SECONDS, reward -4.581667423248291, action 2\n",
      "\n",
      "\n",
      "EPISODE: 172\n",
      "EPISODE DONE IN 2.010862112045288 SECONDS, reward -4.581667423248291, action 0\n",
      "EPISODE DONE IN 4.135254383087158 SECONDS, reward -5.452404499053955, action 5\n",
      "EPISODE DONE IN 6.1671106815338135 SECONDS, reward -16.819149017333984, action 0\n",
      "EPISODE DONE IN 8.075740098953247 SECONDS, reward -14.94920539855957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 173\n",
      "EPISODE DONE IN 1.9039762020111084 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.7992472648620605 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.8233864307403564 SECONDS, reward -4.0137481689453125, action 6\n",
      "EPISODE DONE IN 7.849899530410767 SECONDS, reward -4.0137481689453125, action 0\n",
      "\n",
      "\n",
      "EPISODE: 174\n",
      "EPISODE DONE IN 2.1104495525360107 SECONDS, reward -12.394795417785645, action 7\n",
      "EPISODE DONE IN 4.221614360809326 SECONDS, reward -12.207809448242188, action 5\n",
      "EPISODE DONE IN 6.333187103271484 SECONDS, reward -11.779167175292969, action 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 8.5336012840271 SECONDS, reward -10.850295066833496, action 8\n",
      "\n",
      "\n",
      "EPISODE: 175\n",
      "EPISODE DONE IN 2.205390214920044 SECONDS, reward -2.4581007957458496, action 0\n",
      "EPISODE DONE IN 4.212168216705322 SECONDS, reward -1.524810791015625, action 0\n",
      "EPISODE DONE IN 6.178580045700073 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 8.012309551239014 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 176\n",
      "EPISODE DONE IN 1.7772719860076904 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.93923282623291 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 6.064680099487305 SECONDS, reward -7.137362957000732, action 4\n",
      "EPISODE DONE IN 8.186563968658447 SECONDS, reward -7.515113353729248, action 1\n",
      "\n",
      "\n",
      "EPISODE: 177\n",
      "EPISODE DONE IN 2.126047372817993 SECONDS, reward -7.515113353729248, action 0\n",
      "EPISODE DONE IN 4.127925634384155 SECONDS, reward -6.522812843322754, action 0\n",
      "EPISODE DONE IN 6.063499927520752 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 7.755881309509277 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 178\n",
      "EPISODE DONE IN 1.6893250942230225 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.6181588172912598 SECONDS, reward -14.94920539855957, action 5\n",
      "EPISODE DONE IN 5.685852289199829 SECONDS, reward -5.080244541168213, action 6\n",
      "EPISODE DONE IN 7.720278739929199 SECONDS, reward -5.080244541168213, action 0\n",
      "\n",
      "\n",
      "EPISODE: 179\n",
      "EPISODE DONE IN 2.125317335128784 SECONDS, reward -12.207809448242188, action 7\n",
      "EPISODE DONE IN 4.323439359664917 SECONDS, reward -12.803997993469238, action 1\n",
      "EPISODE DONE IN 6.451259613037109 SECONDS, reward -11.986411094665527, action 2\n",
      "EPISODE DONE IN 8.662296772003174 SECONDS, reward -12.387306213378906, action 5\n",
      "\n",
      "\n",
      "EPISODE: 180\n",
      "EPISODE DONE IN 2.1316885948181152 SECONDS, reward -4.807529926300049, action 0\n",
      "EPISODE DONE IN 4.135263442993164 SECONDS, reward -4.581667423248291, action 0\n",
      "EPISODE DONE IN 6.043961524963379 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.949182987213135 SECONDS, reward -14.926665306091309, action 5\n",
      "\n",
      "\n",
      "EPISODE: 181\n",
      "EPISODE DONE IN 1.9864797592163086 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 4.037655830383301 SECONDS, reward -16.80367088317871, action 2\n",
      "EPISODE DONE IN 6.079359531402588 SECONDS, reward -16.80367088317871, action 0\n",
      "EPISODE DONE IN 7.982733726501465 SECONDS, reward -41.929996490478516, action 0\n",
      "\n",
      "\n",
      "EPISODE: 182\n",
      "EPISODE DONE IN 1.9063613414764404 SECONDS, reward -41.929996490478516, action 0\n",
      "EPISODE DONE IN 3.8079395294189453 SECONDS, reward -41.929996490478516, action 2\n",
      "EPISODE DONE IN 5.714473009109497 SECONDS, reward -41.929996490478516, action 0\n",
      "EPISODE DONE IN 7.745205879211426 SECONDS, reward -16.280006408691406, action 2\n",
      "\n",
      "\n",
      "EPISODE: 183\n",
      "EPISODE DONE IN 2.1284284591674805 SECONDS, reward -17.977354049682617, action 1\n",
      "EPISODE DONE IN 4.156540155410767 SECONDS, reward -35.607975006103516, action 0\n",
      "EPISODE DONE IN 6.185559034347534 SECONDS, reward -35.607975006103516, action 0\n",
      "EPISODE DONE IN 8.250498533248901 SECONDS, reward -21.961380004882812, action 4\n",
      "\n",
      "\n",
      "EPISODE: 184\n",
      "EPISODE DONE IN 1.99137544631958 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 4.1413304805755615 SECONDS, reward -7.004147052764893, action 4\n",
      "EPISODE DONE IN 6.174750566482544 SECONDS, reward -7.004147052764893, action 0\n",
      "EPISODE DONE IN 8.083739757537842 SECONDS, reward -19.564889907836914, action 0\n",
      "\n",
      "\n",
      "EPISODE: 185\n",
      "EPISODE DONE IN 1.9101030826568604 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 3.817448377609253 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.724001884460449 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.7569239139556885 SECONDS, reward -3.7324697971343994, action 7\n",
      "\n",
      "\n",
      "EPISODE: 186\n",
      "EPISODE DONE IN 2.1215670108795166 SECONDS, reward -9.62100887298584, action 4\n",
      "EPISODE DONE IN 4.238819599151611 SECONDS, reward -7.639622211456299, action 8\n",
      "EPISODE DONE IN 6.361621379852295 SECONDS, reward -7.639622211456299, action 0\n",
      "EPISODE DONE IN 8.478652954101562 SECONDS, reward -8.525846481323242, action 1\n",
      "\n",
      "\n",
      "EPISODE: 187\n",
      "EPISODE DONE IN 2.032996892929077 SECONDS, reward -8.778457641601562, action 0\n",
      "EPISODE DONE IN 3.9360790252685547 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.8352439403533936 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 7.7298009395599365 SECONDS, reward -19.538095474243164, action 4\n",
      "\n",
      "\n",
      "EPISODE: 188\n",
      "EPISODE DONE IN 1.905705213546753 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 3.928352117538452 SECONDS, reward -7.004147052764893, action 4\n",
      "EPISODE DONE IN 5.963582992553711 SECONDS, reward -7.004147052764893, action 0\n",
      "EPISODE DONE IN 7.989560604095459 SECONDS, reward -7.224511623382568, action 7\n",
      "\n",
      "\n",
      "EPISODE: 189\n",
      "EPISODE DONE IN 2.0278160572052 SECONDS, reward -7.224511623382568, action 0\n",
      "EPISODE DONE IN 3.921570062637329 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.919132471084595 SECONDS, reward -1.8078097105026245, action 8\n",
      "EPISODE DONE IN 7.814697027206421 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 190\n",
      "EPISODE DONE IN 2.0331194400787354 SECONDS, reward -11.29012680053711, action 6\n",
      "EPISODE DONE IN 4.048009395599365 SECONDS, reward -11.29012680053711, action 0\n",
      "EPISODE DONE IN 5.950698137283325 SECONDS, reward -19.29058074951172, action 0\n",
      "EPISODE DONE IN 7.8478734493255615 SECONDS, reward -19.29058074951172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 191\n",
      "EPISODE DONE IN 1.6580474376678467 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4561514854431152 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.449504375457764 SECONDS, reward -11.80997371673584, action 6\n",
      "EPISODE DONE IN 7.348339796066284 SECONDS, reward -11.80997371673584, action 0\n",
      "\n",
      "\n",
      "EPISODE: 192\n",
      "EPISODE DONE IN 1.9098916053771973 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.8406145572662354 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.66856050491333 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.839266777038574 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 193\n",
      "EPISODE DONE IN 2.0935897827148438 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 4.224545001983643 SECONDS, reward -20.73712730407715, action 4\n",
      "EPISODE DONE IN 6.276496648788452 SECONDS, reward -20.73712730407715, action 0\n",
      "EPISODE DONE IN 8.247846364974976 SECONDS, reward -19.564889907836914, action 0\n",
      "\n",
      "\n",
      "EPISODE: 194\n",
      "EPISODE DONE IN 2.2729544639587402 SECONDS, reward -12.203736305236816, action 4\n",
      "EPISODE DONE IN 4.300115585327148 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 6.477278232574463 SECONDS, reward -15.222729682922363, action 3\n",
      "EPISODE DONE IN 8.548411130905151 SECONDS, reward -15.222729682922363, action 0\n",
      "\n",
      "\n",
      "EPISODE: 195\n",
      "EPISODE DONE IN 1.9118852615356445 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.934368371963501 SECONDS, reward -10.628233909606934, action 7\n",
      "EPISODE DONE IN 5.958860874176025 SECONDS, reward -11.132439613342285, action 2\n",
      "EPISODE DONE IN 7.983279466629028 SECONDS, reward -11.132439613342285, action 0\n",
      "\n",
      "\n",
      "EPISODE: 196\n",
      "EPISODE DONE IN 2.028364658355713 SECONDS, reward -11.132439613342285, action 0\n",
      "EPISODE DONE IN 4.055609464645386 SECONDS, reward -16.280006408691406, action 2\n",
      "EPISODE DONE IN 5.955223560333252 SECONDS, reward -41.929996490478516, action 0\n",
      "EPISODE DONE IN 8.01753544807434 SECONDS, reward -16.60711097717285, action 4\n",
      "\n",
      "\n",
      "EPISODE: 197\n",
      "EPISODE DONE IN 2.1049325466156006 SECONDS, reward -16.60711097717285, action 0\n",
      "EPISODE DONE IN 4.063236951828003 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 6.0636889934539795 SECONDS, reward -7.224181652069092, action 4\n",
      "EPISODE DONE IN 7.9579102993011475 SECONDS, reward -19.538095474243164, action 0\n",
      "\n",
      "\n",
      "EPISODE: 198\n",
      "EPISODE DONE IN 2.0496885776519775 SECONDS, reward -21.961380004882812, action 1\n",
      "EPISODE DONE IN 4.208592414855957 SECONDS, reward -4.9209723472595215, action 7\n",
      "EPISODE DONE IN 6.296351909637451 SECONDS, reward -3.9230270385742188, action 0\n",
      "EPISODE DONE IN 8.38010549545288 SECONDS, reward -3.9230270385742188, action 0\n",
      "\n",
      "\n",
      "EPISODE: 199\n",
      "EPISODE DONE IN 2.010751247406006 SECONDS, reward -10.04487419128418, action 6\n",
      "EPISODE DONE IN 4.001246213912964 SECONDS, reward -10.750896453857422, action 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 5.99777889251709 SECONDS, reward -10.750896453857422, action 0\n",
      "EPISODE DONE IN 7.984438896179199 SECONDS, reward -10.750896453857422, action 0\n",
      "\n",
      "\n",
      "EPISODE: 200\n",
      "EPISODE DONE IN 1.9007959365844727 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 3.5660042762756348 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.31192421913147 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.110466718673706 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 201\n",
      "EPISODE DONE IN 1.7368903160095215 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4700205326080322 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.15343976020813 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.050442457199097 SECONDS, reward -14.926665306091309, action 5\n",
      "\n",
      "\n",
      "EPISODE: 202\n",
      "EPISODE DONE IN 1.9039251804351807 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.807199239730835 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.785823345184326 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.689802169799805 SECONDS, reward -27.10552215576172, action 3\n",
      "\n",
      "\n",
      "EPISODE: 203\n",
      "EPISODE DONE IN 1.9067208766937256 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.8133881092071533 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.816106557846069 SECONDS, reward -1.524810791015625, action 8\n",
      "EPISODE DONE IN 7.719428062438965 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 204\n",
      "EPISODE DONE IN 1.9123404026031494 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 4.017293453216553 SECONDS, reward -5.229360103607178, action 5\n",
      "EPISODE DONE IN 5.93208384513855 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 8.03542709350586 SECONDS, reward -5.199756145477295, action 5\n",
      "\n",
      "\n",
      "EPISODE: 205\n",
      "EPISODE DONE IN 2.0400989055633545 SECONDS, reward -5.199756145477295, action 0\n",
      "EPISODE DONE IN 4.070833921432495 SECONDS, reward -5.086813926696777, action 6\n",
      "EPISODE DONE IN 6.200269937515259 SECONDS, reward -6.152829647064209, action 4\n",
      "EPISODE DONE IN 8.22758936882019 SECONDS, reward -7.137362957000732, action 0\n",
      "\n",
      "\n",
      "EPISODE: 206\n",
      "EPISODE DONE IN 2.0306272506713867 SECONDS, reward -7.137362957000732, action 0\n",
      "EPISODE DONE IN 3.9421865940093994 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.637637615203857 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.549867153167725 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 207\n",
      "EPISODE DONE IN 2.0317184925079346 SECONDS, reward -14.204411506652832, action 3\n",
      "EPISODE DONE IN 4.450760126113892 SECONDS, reward -14.713662147521973, action 1\n",
      "EPISODE DONE IN 6.7809672355651855 SECONDS, reward -8.06868839263916, action 7\n",
      "EPISODE DONE IN 9.07117247581482 SECONDS, reward -14.916240692138672, action 0\n",
      "\n",
      "\n",
      "EPISODE: 208\n",
      "EPISODE DONE IN 2.2381019592285156 SECONDS, reward -10.49156665802002, action 0\n",
      "EPISODE DONE IN 4.1596362590789795 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.875735759735107 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.790438413619995 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 209\n",
      "EPISODE DONE IN 2.0368189811706543 SECONDS, reward -19.22551918029785, action 7\n",
      "EPISODE DONE IN 4.30646014213562 SECONDS, reward -19.22551918029785, action 0\n",
      "EPISODE DONE IN 6.608714818954468 SECONDS, reward -13.810623168945312, action 6\n",
      "EPISODE DONE IN 8.764316082000732 SECONDS, reward -13.120096206665039, action 3\n",
      "\n",
      "\n",
      "EPISODE: 210\n",
      "EPISODE DONE IN 2.0602426528930664 SECONDS, reward -3.2654097080230713, action 0\n",
      "EPISODE DONE IN 4.068575859069824 SECONDS, reward -3.2654097080230713, action 0\n",
      "EPISODE DONE IN 6.10847806930542 SECONDS, reward -3.2654097080230713, action 6\n",
      "EPISODE DONE IN 8.117707014083862 SECONDS, reward -3.3799891471862793, action 1\n",
      "\n",
      "\n",
      "EPISODE: 211\n",
      "EPISODE DONE IN 1.9972126483917236 SECONDS, reward -3.3799891471862793, action 0\n",
      "EPISODE DONE IN 4.211721658706665 SECONDS, reward -5.063669204711914, action 8\n",
      "EPISODE DONE IN 6.24185585975647 SECONDS, reward -8.778457641601562, action 0\n",
      "EPISODE DONE IN 8.149332046508789 SECONDS, reward -7.835620880126953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 212\n",
      "EPISODE DONE IN 1.9940431118011475 SECONDS, reward -6.467592716217041, action 4\n",
      "EPISODE DONE IN 3.8888156414031982 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 5.791622877120972 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 7.6866655349731445 SECONDS, reward -24.511316299438477, action 0\n",
      "\n",
      "\n",
      "EPISODE: 213\n",
      "EPISODE DONE IN 1.6592903137207031 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.624171257019043 SECONDS, reward -14.94920539855957, action 5\n",
      "EPISODE DONE IN 5.602828502655029 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 7.7154929637908936 SECONDS, reward -7.062016487121582, action 4\n",
      "\n",
      "\n",
      "EPISODE: 214\n",
      "EPISODE DONE IN 2.033867835998535 SECONDS, reward -7.062016487121582, action 0\n",
      "EPISODE DONE IN 3.929643392562866 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.89466404914856 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 7.867124080657959 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 215\n",
      "EPISODE DONE IN 1.9169864654541016 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.8167834281921387 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.713303804397583 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.6108245849609375 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 216\n",
      "EPISODE DONE IN 1.894221305847168 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.7842392921447754 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.6785852909088135 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 7.33708381652832 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 217\n",
      "EPISODE DONE IN 1.894683599472046 SECONDS, reward -18.279748916625977, action 7\n",
      "EPISODE DONE IN 3.969191551208496 SECONDS, reward -11.034770011901855, action 4\n",
      "EPISODE DONE IN 5.982945203781128 SECONDS, reward -11.034770011901855, action 0\n",
      "EPISODE DONE IN 8.112375020980835 SECONDS, reward -12.023513793945312, action 6\n",
      "\n",
      "\n",
      "EPISODE: 218\n",
      "EPISODE DONE IN 2.075071334838867 SECONDS, reward -7.129124641418457, action 0\n",
      "EPISODE DONE IN 4.199078321456909 SECONDS, reward -3.738368272781372, action 7\n",
      "EPISODE DONE IN 6.287692308425903 SECONDS, reward -3.738368272781372, action 0\n",
      "EPISODE DONE IN 8.197585344314575 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 219\n",
      "EPISODE DONE IN 1.9021351337432861 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.809851884841919 SECONDS, reward -14.94920539855957, action 5\n",
      "EPISODE DONE IN 5.844314336776733 SECONDS, reward -5.150374412536621, action 7\n",
      "EPISODE DONE IN 7.872521638870239 SECONDS, reward -5.150374412536621, action 0\n",
      "\n",
      "\n",
      "EPISODE: 220\n",
      "EPISODE DONE IN 2.1243207454681396 SECONDS, reward -12.34717082977295, action 6\n",
      "EPISODE DONE IN 4.237401485443115 SECONDS, reward -10.297430038452148, action 8\n",
      "EPISODE DONE IN 6.23313045501709 SECONDS, reward -9.153453826904297, action 0\n",
      "EPISODE DONE IN 8.35509181022644 SECONDS, reward -11.229593276977539, action 1\n",
      "\n",
      "\n",
      "EPISODE: 221\n",
      "EPISODE DONE IN 2.0272982120513916 SECONDS, reward -8.778457641601562, action 0\n",
      "EPISODE DONE IN 4.058152198791504 SECONDS, reward -15.98118782043457, action 5\n",
      "EPISODE DONE IN 6.191340446472168 SECONDS, reward -7.331655502319336, action 4\n",
      "EPISODE DONE IN 8.31173586845398 SECONDS, reward -8.039572715759277, action 3\n",
      "\n",
      "\n",
      "EPISODE: 222\n",
      "EPISODE DONE IN 2.2147042751312256 SECONDS, reward -6.194918632507324, action 3\n",
      "EPISODE DONE IN 4.330711126327515 SECONDS, reward -11.38999080657959, action 0\n",
      "EPISODE DONE IN 6.447955369949341 SECONDS, reward -5.896472930908203, action 8\n",
      "EPISODE DONE IN 8.469354152679443 SECONDS, reward -13.59994888305664, action 0\n",
      "\n",
      "\n",
      "EPISODE: 223\n",
      "EPISODE DONE IN 1.893864393234253 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 3.7860376834869385 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.439255237579346 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.09162974357605 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 224\n",
      "EPISODE DONE IN 1.6544406414031982 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.544922351837158 SECONDS, reward -14.94920539855957, action 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 5.56714129447937 SECONDS, reward -7.062016487121582, action 4\n",
      "EPISODE DONE IN 7.6875975131988525 SECONDS, reward -4.35484504699707, action 6\n",
      "\n",
      "\n",
      "EPISODE: 225\n",
      "EPISODE DONE IN 2.1317503452301025 SECONDS, reward -4.35484504699707, action 0\n",
      "EPISODE DONE IN 4.2487568855285645 SECONDS, reward -4.35484504699707, action 5\n",
      "EPISODE DONE IN 6.271807909011841 SECONDS, reward -5.080244541168213, action 0\n",
      "EPISODE DONE IN 8.166605949401855 SECONDS, reward -14.94920539855957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 226\n",
      "EPISODE DONE IN 1.8968772888183594 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.5467305183410645 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.456000804901123 SECONDS, reward -14.926665306091309, action 5\n",
      "EPISODE DONE IN 7.347124814987183 SECONDS, reward -14.926665306091309, action 0\n",
      "\n",
      "\n",
      "EPISODE: 227\n",
      "EPISODE DONE IN 1.8940863609313965 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.9116575717926025 SECONDS, reward -7.0545878410339355, action 4\n",
      "EPISODE DONE IN 5.94015097618103 SECONDS, reward -10.257720947265625, action 3\n",
      "EPISODE DONE IN 7.960803985595703 SECONDS, reward -10.257720947265625, action 0\n",
      "\n",
      "\n",
      "EPISODE: 228\n",
      "EPISODE DONE IN 2.025012254714966 SECONDS, reward -10.257720947265625, action 0\n",
      "EPISODE DONE IN 3.9151740074157715 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.581443786621094 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.230564117431641 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 229\n",
      "EPISODE DONE IN 1.6541306972503662 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3028292655944824 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.956435441970825 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.605513095855713 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 230\n",
      "EPISODE DONE IN 1.9024085998535156 SECONDS, reward -17.804615020751953, action 8\n",
      "EPISODE DONE IN 3.7923550605773926 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 5.691264867782593 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 7.580429553985596 SECONDS, reward -17.804615020751953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 231\n",
      "EPISODE DONE IN 1.8942060470581055 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 3.78450870513916 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 5.680577516555786 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 7.570299863815308 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 232\n",
      "EPISODE DONE IN 1.6598260402679443 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3094546794891357 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.9633259773254395 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.8566107749938965 SECONDS, reward -14.926665306091309, action 5\n",
      "\n",
      "\n",
      "EPISODE: 233\n",
      "EPISODE DONE IN 1.8961083889007568 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.9132611751556396 SECONDS, reward -5.086813926696777, action 6\n",
      "EPISODE DONE IN 5.934844493865967 SECONDS, reward -5.086813926696777, action 0\n",
      "EPISODE DONE IN 7.828965902328491 SECONDS, reward -11.829377174377441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 234\n",
      "EPISODE DONE IN 1.9951117038726807 SECONDS, reward -9.788493156433105, action 5\n",
      "EPISODE DONE IN 3.8890092372894287 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.78609299659729 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 7.676163196563721 SECONDS, reward -21.154136657714844, action 0\n",
      "\n",
      "\n",
      "EPISODE: 235\n",
      "EPISODE DONE IN 1.894460916519165 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.7842113971710205 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.811269521713257 SECONDS, reward -11.471070289611816, action 8\n",
      "EPISODE DONE IN 7.823220252990723 SECONDS, reward -11.471070289611816, action 0\n",
      "\n",
      "\n",
      "EPISODE: 236\n",
      "EPISODE DONE IN 1.8934822082519531 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 3.783769130706787 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.677967309951782 SECONDS, reward -85.31786346435547, action 1\n",
      "EPISODE DONE IN 7.569482088088989 SECONDS, reward -85.31786346435547, action 0\n",
      "\n",
      "\n",
      "EPISODE: 237\n",
      "EPISODE DONE IN 2.015063762664795 SECONDS, reward -20.259801864624023, action 6\n",
      "EPISODE DONE IN 4.039349555969238 SECONDS, reward -20.259801864624023, action 0\n",
      "EPISODE DONE IN 5.932716608047485 SECONDS, reward -19.29058074951172, action 0\n",
      "EPISODE DONE IN 7.825213432312012 SECONDS, reward -19.29058074951172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 238\n",
      "EPISODE DONE IN 1.6533746719360352 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.30815052986145 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.9632837772369385 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.613177061080933 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 239\n",
      "EPISODE DONE IN 1.6535375118255615 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5441930294036865 SECONDS, reward -7.835620880126953, action 8\n",
      "EPISODE DONE IN 5.566398620605469 SECONDS, reward -2.5109493732452393, action 8\n",
      "EPISODE DONE IN 7.679380893707275 SECONDS, reward -2.9103593826293945, action 6\n",
      "\n",
      "\n",
      "EPISODE: 240\n",
      "EPISODE DONE IN 2.1215713024139404 SECONDS, reward -2.9103593826293945, action 0\n",
      "EPISODE DONE IN 4.239231824874878 SECONDS, reward -3.7189481258392334, action 1\n",
      "EPISODE DONE IN 6.362956762313843 SECONDS, reward -3.3738322257995605, action 2\n",
      "EPISODE DONE IN 8.379300594329834 SECONDS, reward -34.401145935058594, action 0\n",
      "\n",
      "\n",
      "EPISODE: 241\n",
      "EPISODE DONE IN 2.022559404373169 SECONDS, reward -34.401145935058594, action 0\n",
      "EPISODE DONE IN 3.914811372756958 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.569104909896851 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.467625617980957 SECONDS, reward -7.8201141357421875, action 8\n",
      "\n",
      "\n",
      "EPISODE: 242\n",
      "EPISODE DONE IN 1.8954102993011475 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 3.791227102279663 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.694307804107666 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 7.34705376625061 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 243\n",
      "EPISODE DONE IN 1.8950672149658203 SECONDS, reward -30.819826126098633, action 3\n",
      "EPISODE DONE IN 3.7865700721740723 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 5.802079200744629 SECONDS, reward -32.228546142578125, action 1\n",
      "EPISODE DONE IN 7.909060478210449 SECONDS, reward -8.949684143066406, action 5\n",
      "\n",
      "\n",
      "EPISODE: 244\n",
      "EPISODE DONE IN 2.116574287414551 SECONDS, reward -11.940681457519531, action 5\n",
      "EPISODE DONE IN 4.313441514968872 SECONDS, reward -9.79935073852539, action 2\n",
      "EPISODE DONE IN 6.516353368759155 SECONDS, reward -7.6547017097473145, action 7\n",
      "EPISODE DONE IN 8.701030492782593 SECONDS, reward -11.940574645996094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 245\n",
      "EPISODE DONE IN 2.14724063873291 SECONDS, reward -12.3320894241333, action 7\n",
      "EPISODE DONE IN 4.159642457962036 SECONDS, reward -11.899974822998047, action 0\n",
      "EPISODE DONE IN 6.055520057678223 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 8.067378044128418 SECONDS, reward -12.469583511352539, action 6\n",
      "\n",
      "\n",
      "EPISODE: 246\n",
      "EPISODE DONE IN 1.8963220119476318 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.9298794269561768 SECONDS, reward -5.080244541168213, action 5\n",
      "EPISODE DONE IN 5.961140394210815 SECONDS, reward -5.080244541168213, action 0\n",
      "EPISODE DONE IN 7.860728740692139 SECONDS, reward -14.94920539855957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 247\n",
      "EPISODE DONE IN 1.9046435356140137 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.8014283180236816 SECONDS, reward -27.141239166259766, action 3\n",
      "EPISODE DONE IN 5.70905327796936 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 7.605029821395874 SECONDS, reward -27.141239166259766, action 0\n",
      "\n",
      "\n",
      "EPISODE: 248\n",
      "EPISODE DONE IN 1.99472975730896 SECONDS, reward -10.938454627990723, action 7\n",
      "EPISODE DONE IN 3.8895208835601807 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 5.791325569152832 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 7.809619665145874 SECONDS, reward -19.340864181518555, action 3\n",
      "\n",
      "\n",
      "EPISODE: 249\n",
      "EPISODE DONE IN 2.0224342346191406 SECONDS, reward -15.222729682922363, action 4\n",
      "EPISODE DONE IN 4.1378161907196045 SECONDS, reward -10.646151542663574, action 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 6.317119359970093 SECONDS, reward -10.646151542663574, action 0\n",
      "EPISODE DONE IN 8.55425214767456 SECONDS, reward -11.148813247680664, action 6\n",
      "\n",
      "\n",
      "EPISODE: 250\n",
      "EPISODE DONE IN 2.135120391845703 SECONDS, reward -5.080244541168213, action 0\n",
      "EPISODE DONE IN 4.233476161956787 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 6.342333555221558 SECONDS, reward -3.2654097080230713, action 3\n",
      "EPISODE DONE IN 8.328333139419556 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 251\n",
      "EPISODE DONE IN 2.116257905960083 SECONDS, reward -16.56825065612793, action 5\n",
      "EPISODE DONE IN 4.387597560882568 SECONDS, reward -11.449684143066406, action 1\n",
      "EPISODE DONE IN 6.54637336730957 SECONDS, reward -10.696940422058105, action 0\n",
      "EPISODE DONE IN 8.640864133834839 SECONDS, reward -10.696940422058105, action 0\n",
      "\n",
      "\n",
      "EPISODE: 252\n",
      "EPISODE DONE IN 2.015169382095337 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 3.767975330352783 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.537459373474121 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.578455209732056 SECONDS, reward -14.926665306091309, action 5\n",
      "\n",
      "\n",
      "EPISODE: 253\n",
      "EPISODE DONE IN 2.0474934577941895 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.973435640335083 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.926347255706787 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.628218650817871 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 254\n",
      "EPISODE DONE IN 1.962970495223999 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.905369520187378 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.973704099655151 SECONDS, reward -16.56825065612793, action 3\n",
      "EPISODE DONE IN 8.023144960403442 SECONDS, reward -16.56825065612793, action 0\n",
      "\n",
      "\n",
      "EPISODE: 255\n",
      "EPISODE DONE IN 1.9627888202667236 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.928225517272949 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.6657555103302 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.343944787979126 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 256\n",
      "EPISODE DONE IN 1.6708238124847412 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3312227725982666 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.997133255004883 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.656026840209961 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 257\n",
      "EPISODE DONE IN 1.9126863479614258 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 3.9171741008758545 SECONDS, reward -19.302963256835938, action 2\n",
      "EPISODE DONE IN 5.920200347900391 SECONDS, reward -19.302963256835938, action 0\n",
      "EPISODE DONE IN 7.918885946273804 SECONDS, reward -19.302963256835938, action 0\n",
      "\n",
      "\n",
      "EPISODE: 258\n",
      "EPISODE DONE IN 1.9254364967346191 SECONDS, reward -41.929996490478516, action 0\n",
      "EPISODE DONE IN 3.5866713523864746 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.254045248031616 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.915493726730347 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 259\n",
      "EPISODE DONE IN 1.9055569171905518 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 3.805985927581787 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 5.711385011672974 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 7.613238096237183 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 260\n",
      "EPISODE DONE IN 1.6673126220703125 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5713541507720947 SECONDS, reward -9.564072608947754, action 7\n",
      "EPISODE DONE IN 5.60897970199585 SECONDS, reward -7.233112812042236, action 4\n",
      "EPISODE DONE IN 7.639789342880249 SECONDS, reward -7.233112812042236, action 0\n",
      "\n",
      "\n",
      "EPISODE: 261\n",
      "EPISODE DONE IN 2.1234560012817383 SECONDS, reward -12.547009468078613, action 8\n",
      "EPISODE DONE IN 4.241907119750977 SECONDS, reward -12.297874450683594, action 3\n",
      "EPISODE DONE IN 6.246737957000732 SECONDS, reward -11.513713836669922, action 0\n",
      "EPISODE DONE IN 8.250646591186523 SECONDS, reward -11.513713836669922, action 0\n",
      "\n",
      "\n",
      "EPISODE: 262\n",
      "EPISODE DONE IN 1.9108412265777588 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 3.574047565460205 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.241370916366577 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.904500722885132 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 263\n",
      "EPISODE DONE IN 1.6672697067260742 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3319950103759766 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.001333713531494 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.664403915405273 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 264\n",
      "EPISODE DONE IN 1.6663661003112793 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3296520709991455 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.312866687774658 SECONDS, reward -41.876434326171875, action 2\n",
      "EPISODE DONE IN 7.392411231994629 SECONDS, reward -16.841455459594727, action 2\n",
      "\n",
      "\n",
      "EPISODE: 265\n",
      "EPISODE DONE IN 2.121410369873047 SECONDS, reward -16.841455459594727, action 0\n",
      "EPISODE DONE IN 4.175370216369629 SECONDS, reward -16.841455459594727, action 0\n",
      "EPISODE DONE IN 6.182034969329834 SECONDS, reward -1.7058779001235962, action 8\n",
      "EPISODE DONE IN 8.190520286560059 SECONDS, reward -1.8078097105026245, action 7\n",
      "\n",
      "\n",
      "EPISODE: 266\n",
      "EPISODE DONE IN 2.007554769515991 SECONDS, reward -1.8078097105026245, action 0\n",
      "EPISODE DONE IN 4.007352352142334 SECONDS, reward -1.8078097105026245, action 0\n",
      "EPISODE DONE IN 5.9218995571136475 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.921240568161011 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 267\n",
      "EPISODE DONE IN 2.025881290435791 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 4.037545919418335 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 6.18668532371521 SECONDS, reward -3.2654097080230713, action 3\n",
      "EPISODE DONE IN 8.268527507781982 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 268\n",
      "EPISODE DONE IN 2.013683557510376 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.9880118370056152 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.7717366218566895 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.568746089935303 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 269\n",
      "EPISODE DONE IN 1.9440970420837402 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 4.000939846038818 SECONDS, reward -9.788493156433105, action 6\n",
      "EPISODE DONE IN 6.234079837799072 SECONDS, reward -11.240022659301758, action 8\n",
      "EPISODE DONE IN 8.510916233062744 SECONDS, reward -11.240022659301758, action 0\n",
      "\n",
      "\n",
      "EPISODE: 270\n",
      "EPISODE DONE IN 2.193718194961548 SECONDS, reward -3.79691743850708, action 0\n",
      "EPISODE DONE IN 4.249070882797241 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 6.315869092941284 SECONDS, reward -41.876434326171875, action 2\n",
      "EPISODE DONE IN 8.36324954032898 SECONDS, reward -41.876434326171875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 271\n",
      "EPISODE DONE IN 2.0193490982055664 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 4.081218957901001 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.809889316558838 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.499391794204712 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 272\n",
      "EPISODE DONE IN 1.7255439758300781 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4147419929504395 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.211836338043213 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.882958650588989 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 273\n",
      "EPISODE DONE IN 1.7790772914886475 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.500312328338623 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.166153430938721 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.069375038146973 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 274\n",
      "EPISODE DONE IN 1.9050209522247314 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.8065195083618164 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.716641426086426 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 7.373058080673218 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 1.6641488075256348 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3189215660095215 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.218951463699341 SECONDS, reward -19.538095474243164, action 4\n",
      "EPISODE DONE IN 7.115889072418213 SECONDS, reward -19.538095474243164, action 0\n",
      "\n",
      "\n",
      "EPISODE: 276\n",
      "EPISODE DONE IN 1.8990733623504639 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 3.7935101985931396 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.452894926071167 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.107717037200928 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 277\n",
      "EPISODE DONE IN 1.663886308670044 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.56138277053833 SECONDS, reward -41.929996490478516, action 2\n",
      "EPISODE DONE IN 5.587130069732666 SECONDS, reward -16.280006408691406, action 2\n",
      "EPISODE DONE IN 7.708628177642822 SECONDS, reward -4.996547698974609, action 5\n",
      "\n",
      "\n",
      "EPISODE: 278\n",
      "EPISODE DONE IN 2.208744764328003 SECONDS, reward -10.995491027832031, action 7\n",
      "EPISODE DONE IN 4.417216777801514 SECONDS, reward -10.616843223571777, action 3\n",
      "EPISODE DONE IN 6.533068656921387 SECONDS, reward -11.828744888305664, action 0\n",
      "EPISODE DONE IN 8.529215574264526 SECONDS, reward -10.938454627990723, action 0\n",
      "\n",
      "\n",
      "EPISODE: 279\n",
      "EPISODE DONE IN 2.0137248039245605 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 3.7233800888061523 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.687950134277344 SECONDS, reward -19.538095474243164, action 4\n",
      "EPISODE DONE IN 7.616990089416504 SECONDS, reward -19.538095474243164, action 0\n",
      "\n",
      "\n",
      "EPISODE: 280\n",
      "EPISODE DONE IN 1.9416062831878662 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 3.866547107696533 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.602417945861816 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.279385089874268 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 281\n",
      "EPISODE DONE IN 1.9333186149597168 SECONDS, reward -24.511316299438477, action 4\n",
      "EPISODE DONE IN 3.8628764152526855 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 5.770348072052002 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 7.667874574661255 SECONDS, reward -24.511316299438477, action 0\n",
      "\n",
      "\n",
      "EPISODE: 282\n",
      "EPISODE DONE IN 1.6612379550933838 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.361955404281616 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.072564601898193 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.9722819328308105 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 283\n",
      "EPISODE DONE IN 1.9040045738220215 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.7996926307678223 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.7048444747924805 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 7.403317213058472 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 284\n",
      "EPISODE DONE IN 1.9546101093292236 SECONDS, reward -17.804615020751953, action 8\n",
      "EPISODE DONE IN 3.8951525688171387 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 5.825146198272705 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 7.758241176605225 SECONDS, reward -17.804615020751953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 285\n",
      "EPISODE DONE IN 1.718862771987915 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4471373558044434 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.461024045944214 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 7.616028308868408 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 286\n",
      "EPISODE DONE IN 2.10412335395813 SECONDS, reward -11.29012680053711, action 6\n",
      "EPISODE DONE IN 4.30276346206665 SECONDS, reward -11.29012680053711, action 0\n",
      "EPISODE DONE IN 6.37004280090332 SECONDS, reward -20.98308563232422, action 2\n",
      "EPISODE DONE IN 8.446429014205933 SECONDS, reward -20.98308563232422, action 0\n",
      "\n",
      "\n",
      "EPISODE: 287\n",
      "EPISODE DONE IN 2.102996826171875 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 4.1466169357299805 SECONDS, reward -16.280006408691406, action 2\n",
      "EPISODE DONE IN 6.193133115768433 SECONDS, reward -16.280006408691406, action 2\n",
      "EPISODE DONE IN 8.23112440109253 SECONDS, reward -16.280006408691406, action 0\n",
      "\n",
      "\n",
      "EPISODE: 288\n",
      "EPISODE DONE IN 2.0960617065429688 SECONDS, reward -16.280006408691406, action 0\n",
      "EPISODE DONE IN 4.179292917251587 SECONDS, reward -11.132439613342285, action 7\n",
      "EPISODE DONE IN 6.159563064575195 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 8.384156227111816 SECONDS, reward -11.132439613342285, action 2\n",
      "\n",
      "\n",
      "EPISODE: 289\n",
      "EPISODE DONE IN 2.16129994392395 SECONDS, reward -4.501160144805908, action 1\n",
      "EPISODE DONE IN 4.288179874420166 SECONDS, reward -35.607975006103516, action 0\n",
      "EPISODE DONE IN 6.429224014282227 SECONDS, reward -18.317752838134766, action 2\n",
      "EPISODE DONE IN 8.58050799369812 SECONDS, reward -6.037313461303711, action 5\n",
      "\n",
      "\n",
      "EPISODE: 290\n",
      "EPISODE DONE IN 2.016094207763672 SECONDS, reward -4.581667423248291, action 0\n",
      "EPISODE DONE IN 4.024114370346069 SECONDS, reward -4.581667423248291, action 0\n",
      "EPISODE DONE IN 5.9339540004730225 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.604980230331421 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 291\n",
      "EPISODE DONE IN 1.9268560409545898 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 3.9926602840423584 SECONDS, reward -7.077223777770996, action 5\n",
      "EPISODE DONE IN 5.999843120574951 SECONDS, reward -7.077223777770996, action 0\n",
      "EPISODE DONE IN 7.988795042037964 SECONDS, reward -7.077223777770996, action 0\n",
      "\n",
      "\n",
      "EPISODE: 292\n",
      "EPISODE DONE IN 1.9062058925628662 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.5707309246063232 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.2286152839660645 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.12668514251709 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 293\n",
      "EPISODE DONE IN 1.903111219406128 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.803022623062134 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.878918170928955 SECONDS, reward -2.2498552799224854, action 2\n",
      "EPISODE DONE IN 7.958824634552002 SECONDS, reward -2.2498552799224854, action 7\n",
      "\n",
      "\n",
      "EPISODE: 294\n",
      "EPISODE DONE IN 2.0036633014678955 SECONDS, reward -2.2498552799224854, action 0\n",
      "EPISODE DONE IN 4.123005390167236 SECONDS, reward -3.592550754547119, action 7\n",
      "EPISODE DONE IN 6.154572486877441 SECONDS, reward -3.1596837043762207, action 0\n",
      "EPISODE DONE IN 8.054114818572998 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 295\n",
      "EPISODE DONE IN 1.994760274887085 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.765101671218872 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.53180193901062 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.267950534820557 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 296\n",
      "EPISODE DONE IN 1.999032974243164 SECONDS, reward -18.279748916625977, action 7\n",
      "EPISODE DONE IN 3.893428325653076 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 5.792148590087891 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 7.987034797668457 SECONDS, reward -13.88493537902832, action 5\n",
      "\n",
      "\n",
      "EPISODE: 297\n",
      "EPISODE DONE IN 2.0393409729003906 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.9368691444396973 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.841442346572876 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.495595455169678 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 298\n",
      "EPISODE DONE IN 1.6626458168029785 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3192574977874756 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.23125433921814 SECONDS, reward -27.10552215576172, action 3\n",
      "EPISODE DONE IN 7.138550519943237 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 299\n",
      "EPISODE DONE IN 1.971348762512207 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.9476571083068848 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.961153268814087 SECONDS, reward -41.876434326171875, action 2\n",
      "EPISODE DONE IN 8.065011978149414 SECONDS, reward -4.581667423248291, action 5\n",
      "\n",
      "\n",
      "EPISODE: 300\n",
      "EPISODE DONE IN 2.0136494636535645 SECONDS, reward -4.581667423248291, action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 4.0173375606536865 SECONDS, reward -4.581667423248291, action 0\n",
      "EPISODE DONE IN 6.020898818969727 SECONDS, reward -3.5406901836395264, action 6\n",
      "EPISODE DONE IN 7.922400236129761 SECONDS, reward -11.80997371673584, action 0\n",
      "\n",
      "\n",
      "EPISODE: 301\n",
      "EPISODE DONE IN 1.9672858715057373 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 4.089681386947632 SECONDS, reward -4.0137481689453125, action 6\n",
      "EPISODE DONE IN 6.006315231323242 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.979003190994263 SECONDS, reward -11.829377174377441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 302\n",
      "EPISODE DONE IN 1.9875061511993408 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 3.6633386611938477 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.328430414199829 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.229116439819336 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 303\n",
      "EPISODE DONE IN 1.9119513034820557 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.9401395320892334 SECONDS, reward -34.00605392456055, action 1\n",
      "EPISODE DONE IN 5.971346616744995 SECONDS, reward -34.00605392456055, action 0\n",
      "EPISODE DONE IN 7.871797561645508 SECONDS, reward -85.42497253417969, action 0\n",
      "\n",
      "\n",
      "EPISODE: 304\n",
      "EPISODE DONE IN 1.977186918258667 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 3.6979591846466064 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.413056373596191 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.125393867492676 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 305\n",
      "EPISODE DONE IN 1.6674325466156006 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3313982486724854 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.313867807388306 SECONDS, reward -85.31786346435547, action 1\n",
      "EPISODE DONE IN 7.212773561477661 SECONDS, reward -85.31786346435547, action 0\n",
      "\n",
      "\n",
      "EPISODE: 306\n",
      "EPISODE DONE IN 1.9085133075714111 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.930173635482788 SECONDS, reward -10.50883960723877, action 7\n",
      "EPISODE DONE IN 5.834928512573242 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 7.734559535980225 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 307\n",
      "EPISODE DONE IN 1.9982287883758545 SECONDS, reward -11.796281814575195, action 8\n",
      "EPISODE DONE IN 3.8993020057678223 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 5.997591733932495 SECONDS, reward -15.213788986206055, action 5\n",
      "EPISODE DONE IN 8.02157473564148 SECONDS, reward -15.213788986206055, action 0\n",
      "\n",
      "\n",
      "EPISODE: 308\n",
      "EPISODE DONE IN 1.9061260223388672 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.8731651306152344 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.654860973358154 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.4955666065216064 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 309\n",
      "EPISODE DONE IN 2.1012909412384033 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 4.1648571491241455 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 6.2640461921691895 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 8.44766116142273 SECONDS, reward -19.08458137512207, action 4\n",
      "\n",
      "\n",
      "EPISODE: 310\n",
      "EPISODE DONE IN 2.0606467723846436 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 4.144164800643921 SECONDS, reward -7.233112812042236, action 7\n",
      "EPISODE DONE IN 6.259641170501709 SECONDS, reward -7.233112812042236, action 0\n",
      "EPISODE DONE IN 8.206692934036255 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 311\n",
      "EPISODE DONE IN 2.0603268146514893 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.761308431625366 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.477557182312012 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.411597490310669 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 312\n",
      "EPISODE DONE IN 1.9063308238983154 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.8305227756500244 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.887976408004761 SECONDS, reward -3.5406901836395264, action 5\n",
      "EPISODE DONE IN 7.788094997406006 SECONDS, reward -14.926665306091309, action 0\n",
      "\n",
      "\n",
      "EPISODE: 313\n",
      "EPISODE DONE IN 1.9094765186309814 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.957735300064087 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 6.018395662307739 SECONDS, reward -19.538095474243164, action 4\n",
      "EPISODE DONE IN 8.017928838729858 SECONDS, reward -19.538095474243164, action 0\n",
      "\n",
      "\n",
      "EPISODE: 314\n",
      "EPISODE DONE IN 2.031855821609497 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 4.031362533569336 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.778722763061523 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.4751763343811035 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 315\n",
      "EPISODE DONE IN 1.7702956199645996 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.7305290699005127 SECONDS, reward -19.564889907836914, action 4\n",
      "EPISODE DONE IN 5.669775485992432 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 7.640106201171875 SECONDS, reward -19.564889907836914, action 0\n",
      "\n",
      "\n",
      "EPISODE: 316\n",
      "EPISODE DONE IN 2.0621116161346436 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 3.791163921356201 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.485455513000488 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.481088638305664 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 317\n",
      "EPISODE DONE IN 1.9853782653808594 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.964886426925659 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.949893951416016 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.631674528121948 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 318\n",
      "EPISODE DONE IN 1.6672337055206299 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.330132484436035 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.236518383026123 SECONDS, reward -9.546906471252441, action 7\n",
      "EPISODE DONE IN 7.138228893280029 SECONDS, reward -9.546906471252441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 319\n",
      "EPISODE DONE IN 1.9095971584320068 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 4.010661602020264 SECONDS, reward -7.224511623382568, action 4\n",
      "EPISODE DONE IN 5.920264720916748 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 7.823756694793701 SECONDS, reward -19.564889907836914, action 0\n",
      "\n",
      "\n",
      "EPISODE: 320\n",
      "EPISODE DONE IN 1.9076340198516846 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 3.6430585384368896 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.55058741569519 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 7.548274993896484 SECONDS, reward -1.468550443649292, action 4\n",
      "\n",
      "\n",
      "EPISODE: 321\n",
      "EPISODE DONE IN 2.12439227104187 SECONDS, reward -4.774501800537109, action 1\n",
      "EPISODE DONE IN 4.250345706939697 SECONDS, reward -4.774501800537109, action 0\n",
      "EPISODE DONE IN 6.278304576873779 SECONDS, reward -21.961380004882812, action 0\n",
      "EPISODE DONE IN 8.17781925201416 SECONDS, reward -86.46080780029297, action 0\n",
      "\n",
      "\n",
      "EPISODE: 322\n",
      "EPISODE DONE IN 1.9783174991607666 SECONDS, reward -86.46080780029297, action 1\n",
      "EPISODE DONE IN 4.050617694854736 SECONDS, reward -5.7081217765808105, action 5\n",
      "EPISODE DONE IN 6.232573509216309 SECONDS, reward -6.4625725746154785, action 3\n",
      "EPISODE DONE IN 8.481460571289062 SECONDS, reward -6.4625725746154785, action 0\n",
      "\n",
      "\n",
      "EPISODE: 323\n",
      "EPISODE DONE IN 2.1904959678649902 SECONDS, reward -7.657741069793701, action 2\n",
      "EPISODE DONE IN 4.309730291366577 SECONDS, reward -4.869734287261963, action 8\n",
      "EPISODE DONE IN 6.388664245605469 SECONDS, reward -4.207798004150391, action 0\n",
      "EPISODE DONE IN 8.387261390686035 SECONDS, reward -4.207798004150391, action 0\n",
      "\n",
      "\n",
      "EPISODE: 324\n",
      "EPISODE DONE IN 1.9983925819396973 SECONDS, reward -5.276650905609131, action 3\n",
      "EPISODE DONE IN 3.9928414821624756 SECONDS, reward -5.949560642242432, action 7\n",
      "EPISODE DONE IN 5.993657112121582 SECONDS, reward -5.949560642242432, action 0\n",
      "EPISODE DONE IN 8.112375259399414 SECONDS, reward -7.270226955413818, action 8\n",
      "\n",
      "\n",
      "EPISODE: 325\n",
      "EPISODE DONE IN 2.1225967407226562 SECONDS, reward -12.855767250061035, action 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 4.143451452255249 SECONDS, reward -11.591934204101562, action 0\n",
      "EPISODE DONE IN 6.167480230331421 SECONDS, reward -11.591934204101562, action 0\n",
      "EPISODE DONE IN 8.069846630096436 SECONDS, reward -18.279748916625977, action 0\n",
      "\n",
      "\n",
      "EPISODE: 326\n",
      "EPISODE DONE IN 1.6624467372894287 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.387907028198242 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.050633668899536 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.808851957321167 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 327\n",
      "EPISODE DONE IN 1.799426794052124 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5571093559265137 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.363576650619507 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.138782024383545 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 328\n",
      "EPISODE DONE IN 1.8390049934387207 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.8518335819244385 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.52170729637146 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.417547225952148 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 329\n",
      "EPISODE DONE IN 1.9041261672973633 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.795841932296753 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.704815149307251 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 7.358050584793091 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 330\n",
      "EPISODE DONE IN 1.6622421741485596 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.562074899673462 SECONDS, reward -19.564889907836914, action 4\n",
      "EPISODE DONE IN 5.46379017829895 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 7.519405364990234 SECONDS, reward -20.73712730407715, action 1\n",
      "\n",
      "\n",
      "EPISODE: 331\n",
      "EPISODE DONE IN 2.041351318359375 SECONDS, reward -20.73712730407715, action 0\n",
      "EPISODE DONE IN 4.071359395980835 SECONDS, reward -28.549123764038086, action 3\n",
      "EPISODE DONE IN 6.100384712219238 SECONDS, reward -28.549123764038086, action 0\n",
      "EPISODE DONE IN 8.002291202545166 SECONDS, reward -27.141239166259766, action 0\n",
      "\n",
      "\n",
      "EPISODE: 332\n",
      "EPISODE DONE IN 1.993180751800537 SECONDS, reward -14.264087677001953, action 3\n",
      "EPISODE DONE IN 3.891364336013794 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 5.7912492752075195 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 7.811006546020508 SECONDS, reward -32.228546142578125, action 1\n",
      "\n",
      "\n",
      "EPISODE: 333\n",
      "EPISODE DONE IN 2.0268490314483643 SECONDS, reward -25.68418312072754, action 4\n",
      "EPISODE DONE IN 4.040467977523804 SECONDS, reward -25.68418312072754, action 0\n",
      "EPISODE DONE IN 6.156733512878418 SECONDS, reward -26.68055534362793, action 1\n",
      "EPISODE DONE IN 8.171224355697632 SECONDS, reward -25.68418312072754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 334\n",
      "EPISODE DONE IN 2.0260019302368164 SECONDS, reward -18.748390197753906, action 8\n",
      "EPISODE DONE IN 4.134695053100586 SECONDS, reward -13.514300346374512, action 4\n",
      "EPISODE DONE IN 6.128622531890869 SECONDS, reward -11.456500053405762, action 0\n",
      "EPISODE DONE IN 8.11682391166687 SECONDS, reward -11.456500053405762, action 0\n",
      "\n",
      "\n",
      "EPISODE: 335\n",
      "EPISODE DONE IN 1.899916648864746 SECONDS, reward -19.564889907836914, action 0\n",
      "EPISODE DONE IN 3.797241449356079 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.7107977867126465 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.61140513420105 SECONDS, reward -11.829377174377441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 336\n",
      "EPISODE DONE IN 1.9016015529632568 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 3.555105686187744 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.216849088668823 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.870303392410278 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 337\n",
      "EPISODE DONE IN 1.6616487503051758 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.556678056716919 SECONDS, reward -41.929996490478516, action 2\n",
      "EPISODE DONE IN 5.5908379554748535 SECONDS, reward -13.499977111816406, action 6\n",
      "EPISODE DONE IN 7.618478775024414 SECONDS, reward -13.499977111816406, action 0\n",
      "\n",
      "\n",
      "EPISODE: 338\n",
      "EPISODE DONE IN 2.1151270866394043 SECONDS, reward -12.816024780273438, action 4\n",
      "EPISODE DONE IN 4.129912614822388 SECONDS, reward -12.118247985839844, action 0\n",
      "EPISODE DONE IN 6.030937433242798 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 7.924987077713013 SECONDS, reward -24.511316299438477, action 0\n",
      "\n",
      "\n",
      "EPISODE: 339\n",
      "EPISODE DONE IN 1.6651623249053955 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.559051752090454 SECONDS, reward -41.929996490478516, action 2\n",
      "EPISODE DONE IN 5.589539051055908 SECONDS, reward -9.3179349899292, action 8\n",
      "EPISODE DONE IN 7.615517616271973 SECONDS, reward -9.3179349899292, action 0\n",
      "\n",
      "\n",
      "EPISODE: 340\n",
      "EPISODE DONE IN 2.0257201194763184 SECONDS, reward -9.3179349899292, action 0\n",
      "EPISODE DONE IN 3.9209630489349365 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.582191228866577 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.47772216796875 SECONDS, reward -14.926665306091309, action 5\n",
      "\n",
      "\n",
      "EPISODE: 341\n",
      "EPISODE DONE IN 1.9066600799560547 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.79986310005188 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.701526403427124 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 7.355036497116089 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 342\n",
      "EPISODE DONE IN 1.9022700786590576 SECONDS, reward -17.804615020751953, action 8\n",
      "EPISODE DONE IN 3.7966339588165283 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 5.699358940124512 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 7.713809490203857 SECONDS, reward -18.748390197753906, action 1\n",
      "\n",
      "\n",
      "EPISODE: 343\n",
      "EPISODE DONE IN 2.0213418006896973 SECONDS, reward -32.228546142578125, action 3\n",
      "EPISODE DONE IN 4.140083074569702 SECONDS, reward -13.749991416931152, action 1\n",
      "EPISODE DONE IN 6.349185943603516 SECONDS, reward -7.350226402282715, action 8\n",
      "EPISODE DONE IN 8.461666584014893 SECONDS, reward -14.17827033996582, action 0\n",
      "\n",
      "\n",
      "EPISODE: 344\n",
      "EPISODE DONE IN 2.032040596008301 SECONDS, reward -8.762864112854004, action 0\n",
      "EPISODE DONE IN 3.927076578140259 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.589479207992554 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.242955446243286 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 345\n",
      "EPISODE DONE IN 1.9022204875946045 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.794340133666992 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.696514844894409 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 7.592747211456299 SECONDS, reward -21.154136657714844, action 0\n",
      "\n",
      "\n",
      "EPISODE: 346\n",
      "EPISODE DONE IN 1.8992705345153809 SECONDS, reward -24.511316299438477, action 4\n",
      "EPISODE DONE IN 3.8826208114624023 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 6.010298728942871 SECONDS, reward -12.21383285522461, action 7\n",
      "EPISODE DONE IN 8.033295154571533 SECONDS, reward -12.21383285522461, action 0\n",
      "\n",
      "\n",
      "EPISODE: 347\n",
      "EPISODE DONE IN 1.9001579284667969 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.7919609546661377 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.692373752593994 SECONDS, reward -14.926665306091309, action 5\n",
      "EPISODE DONE IN 7.5855467319488525 SECONDS, reward -14.926665306091309, action 0\n",
      "\n",
      "\n",
      "EPISODE: 348\n",
      "EPISODE DONE IN 1.8977513313293457 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.7896368503570557 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.695291042327881 SECONDS, reward -27.10552215576172, action 3\n",
      "EPISODE DONE IN 7.5868518352508545 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 349\n",
      "EPISODE DONE IN 2.02401065826416 SECONDS, reward -17.943557739257812, action 6\n",
      "EPISODE DONE IN 4.129298686981201 SECONDS, reward -9.763203620910645, action 8\n",
      "EPISODE DONE IN 6.124798774719238 SECONDS, reward -9.153453826904297, action 0\n",
      "EPISODE DONE IN 8.110570430755615 SECONDS, reward -9.153453826904297, action 0\n",
      "\n",
      "\n",
      "EPISODE: 350\n",
      "EPISODE DONE IN 1.9015634059906006 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 3.5526766777038574 SECONDS, reward -10000000.0, action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 5.211595296859741 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.10297966003418 SECONDS, reward -41.876434326171875, action 2\n",
      "\n",
      "\n",
      "EPISODE: 351\n",
      "EPISODE DONE IN 1.8996989727020264 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 3.8074193000793457 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.808168649673462 SECONDS, reward -10.170105934143066, action 3\n",
      "EPISODE DONE IN 7.702329635620117 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 352\n",
      "EPISODE DONE IN 1.9027774333953857 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.865398406982422 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.536283016204834 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.1896398067474365 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 353\n",
      "EPISODE DONE IN 1.9063529968261719 SECONDS, reward -24.511316299438477, action 4\n",
      "EPISODE DONE IN 3.8909053802490234 SECONDS, reward -9.923580169677734, action 5\n",
      "EPISODE DONE IN 5.885938882827759 SECONDS, reward -9.923580169677734, action 0\n",
      "EPISODE DONE IN 7.996068716049194 SECONDS, reward -10.446008682250977, action 2\n",
      "\n",
      "\n",
      "EPISODE: 354\n",
      "EPISODE DONE IN 2.1198337078094482 SECONDS, reward -6.201836585998535, action 1\n",
      "EPISODE DONE IN 4.230859756469727 SECONDS, reward -17.977354049682617, action 2\n",
      "EPISODE DONE IN 6.442232131958008 SECONDS, reward -4.342547416687012, action 3\n",
      "EPISODE DONE IN 8.551233530044556 SECONDS, reward -18.27240562438965, action 0\n",
      "\n",
      "\n",
      "EPISODE: 355\n",
      "EPISODE DONE IN 2.025698661804199 SECONDS, reward -16.42769432067871, action 0\n",
      "EPISODE DONE IN 4.047052621841431 SECONDS, reward -10.353653907775879, action 5\n",
      "EPISODE DONE IN 6.07568621635437 SECONDS, reward -5.080244541168213, action 6\n",
      "EPISODE DONE IN 8.094378232955933 SECONDS, reward -5.080244541168213, action 0\n",
      "\n",
      "\n",
      "EPISODE: 356\n",
      "EPISODE DONE IN 2.0265731811523438 SECONDS, reward -5.080244541168213, action 0\n",
      "EPISODE DONE IN 3.981886625289917 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.660292863845825 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.558062791824341 SECONDS, reward -41.876434326171875, action 2\n",
      "\n",
      "\n",
      "EPISODE: 357\n",
      "EPISODE DONE IN 1.9008543491363525 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 3.922884225845337 SECONDS, reward -16.280006408691406, action 2\n",
      "EPISODE DONE IN 5.952165126800537 SECONDS, reward -16.280006408691406, action 0\n",
      "EPISODE DONE IN 7.852061986923218 SECONDS, reward -41.929996490478516, action 0\n",
      "\n",
      "\n",
      "EPISODE: 358\n",
      "EPISODE DONE IN 1.8989644050598145 SECONDS, reward -41.929996490478516, action 0\n",
      "EPISODE DONE IN 3.551347255706787 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.212032794952393 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.8680970668792725 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 359\n",
      "EPISODE DONE IN 1.6619946956634521 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3171398639678955 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.224157094955444 SECONDS, reward -11.80997371673584, action 6\n",
      "EPISODE DONE IN 7.221209287643433 SECONDS, reward -3.396500587463379, action 4\n",
      "\n",
      "\n",
      "EPISODE: 360\n",
      "EPISODE DONE IN 1.9983842372894287 SECONDS, reward -3.396500587463379, action 0\n",
      "EPISODE DONE IN 3.9906249046325684 SECONDS, reward -3.396500587463379, action 0\n",
      "EPISODE DONE IN 5.89205265045166 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 7.550740957260132 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 361\n",
      "EPISODE DONE IN 1.6573634147644043 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.552948474884033 SECONDS, reward -9.564072608947754, action 7\n",
      "EPISODE DONE IN 5.455740451812744 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 7.352653503417969 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 362\n",
      "EPISODE DONE IN 2.020632266998291 SECONDS, reward -11.471667289733887, action 7\n",
      "EPISODE DONE IN 3.9246060848236084 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 5.954291343688965 SECONDS, reward -19.8499813079834, action 2\n",
      "EPISODE DONE IN 8.068246126174927 SECONDS, reward -12.332727432250977, action 7\n",
      "\n",
      "\n",
      "EPISODE: 363\n",
      "EPISODE DONE IN 1.9978101253509521 SECONDS, reward -2.2498552799224854, action 0\n",
      "EPISODE DONE IN 3.9927659034729004 SECONDS, reward -2.2498552799224854, action 0\n",
      "EPISODE DONE IN 5.893413305282593 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.5465381145477295 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 364\n",
      "EPISODE DONE IN 1.6593804359436035 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.554032802581787 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.460739612579346 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.357837438583374 SECONDS, reward -11.829377174377441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 365\n",
      "EPISODE DONE IN 1.8994083404541016 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 3.5515239238739014 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.213037729263306 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.865943431854248 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 366\n",
      "EPISODE DONE IN 1.6631135940551758 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.343421220779419 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.059888601303101 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.723002672195435 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 367\n",
      "EPISODE DONE IN 1.6687910556793213 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3321003913879395 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.00178074836731 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.665005922317505 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 368\n",
      "EPISODE DONE IN 1.6701688766479492 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.6455585956573486 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.765638589859009 SECONDS, reward -4.0137481689453125, action 6\n",
      "EPISODE DONE IN 7.793105840682983 SECONDS, reward -4.0137481689453125, action 0\n",
      "\n",
      "\n",
      "EPISODE: 369\n",
      "EPISODE DONE IN 2.0332698822021484 SECONDS, reward -4.0137481689453125, action 0\n",
      "EPISODE DONE IN 4.06225848197937 SECONDS, reward -3.738368272781372, action 7\n",
      "EPISODE DONE IN 5.974447727203369 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 7.8782570362091064 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 370\n",
      "EPISODE DONE IN 1.9051299095153809 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.559858560562134 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.463513612747192 SECONDS, reward -11.80997371673584, action 6\n",
      "EPISODE DONE IN 7.369267702102661 SECONDS, reward -11.80997371673584, action 0\n",
      "\n",
      "\n",
      "EPISODE: 371\n",
      "EPISODE DONE IN 1.9094927310943604 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.812448740005493 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.471010446548462 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.12301230430603 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 372\n",
      "EPISODE DONE IN 1.657588005065918 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.554044246673584 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.454118490219116 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.3482465744018555 SECONDS, reward -11.829377174377441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 373\n",
      "EPISODE DONE IN 1.9018685817718506 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 3.554410934448242 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.452829837799072 SECONDS, reward -11.80997371673584, action 6\n",
      "EPISODE DONE IN 7.3470778465271 SECONDS, reward -11.80997371673584, action 0\n",
      "\n",
      "\n",
      "EPISODE: 374\n",
      "EPISODE DONE IN 1.8978955745697021 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.789750337600708 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.448984622955322 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.100144624710083 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 375\n",
      "EPISODE DONE IN 1.6594924926757812 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5533699989318848 SECONDS, reward -7.835620880126953, action 8\n",
      "EPISODE DONE IN 5.5261876583099365 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 7.434702157974243 SECONDS, reward -7.835620880126953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 1.9055166244506836 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 3.557739734649658 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.216783046722412 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.870137691497803 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 377\n",
      "EPISODE DONE IN 1.6580309867858887 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3094358444213867 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.9680235385894775 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.637718200683594 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 378\n",
      "EPISODE DONE IN 1.7119777202606201 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.6029863357543945 SECONDS, reward -85.42497253417969, action 1\n",
      "EPISODE DONE IN 5.588895082473755 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 7.710672616958618 SECONDS, reward -34.00605392456055, action 1\n",
      "\n",
      "\n",
      "EPISODE: 379\n",
      "EPISODE DONE IN 2.1207447052001953 SECONDS, reward -36.4188117980957, action 1\n",
      "EPISODE DONE IN 4.229843854904175 SECONDS, reward -11.265650749206543, action 3\n",
      "EPISODE DONE IN 6.345248222351074 SECONDS, reward -11.265650749206543, action 0\n",
      "EPISODE DONE IN 8.332680940628052 SECONDS, reward -11.102371215820312, action 0\n",
      "\n",
      "\n",
      "EPISODE: 380\n",
      "EPISODE DONE IN 1.9015803337097168 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 3.8001821041107178 SECONDS, reward -41.929996490478516, action 2\n",
      "EPISODE DONE IN 5.7004804611206055 SECONDS, reward -41.929996490478516, action 0\n",
      "EPISODE DONE IN 7.593625783920288 SECONDS, reward -41.929996490478516, action 0\n",
      "\n",
      "\n",
      "EPISODE: 381\n",
      "EPISODE DONE IN 1.9931154251098633 SECONDS, reward -10.81537914276123, action 5\n",
      "EPISODE DONE IN 3.886335849761963 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.905402421951294 SECONDS, reward -23.01586151123047, action 2\n",
      "EPISODE DONE IN 7.918771505355835 SECONDS, reward -23.01586151123047, action 0\n",
      "\n",
      "\n",
      "EPISODE: 382\n",
      "EPISODE DONE IN 1.8998839855194092 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 3.9207611083984375 SECONDS, reward -16.44278907775879, action 3\n",
      "EPISODE DONE IN 5.944358587265015 SECONDS, reward -28.549123764038086, action 1\n",
      "EPISODE DONE IN 7.964580059051514 SECONDS, reward -28.549123764038086, action 0\n",
      "\n",
      "\n",
      "EPISODE: 383\n",
      "EPISODE DONE IN 2.024024486541748 SECONDS, reward -28.549123764038086, action 0\n",
      "EPISODE DONE IN 3.918126106262207 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.817303657531738 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 7.712096929550171 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 384\n",
      "EPISODE DONE IN 2.0232295989990234 SECONDS, reward -13.59994888305664, action 3\n",
      "EPISODE DONE IN 4.037916421890259 SECONDS, reward -13.59994888305664, action 0\n",
      "EPISODE DONE IN 6.062902927398682 SECONDS, reward -14.07841682434082, action 5\n",
      "EPISODE DONE IN 8.078221321105957 SECONDS, reward -14.07841682434082, action 0\n",
      "\n",
      "\n",
      "EPISODE: 385\n",
      "EPISODE DONE IN 1.8991878032684326 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.794278383255005 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.456542253494263 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.108180999755859 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 386\n",
      "EPISODE DONE IN 1.6588537693023682 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3093509674072266 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.969209671020508 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.62119722366333 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 387\n",
      "EPISODE DONE IN 1.6588401794433594 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.353602409362793 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.0439372062683105 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.694942235946655 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 388\n",
      "EPISODE DONE IN 1.8984177112579346 SECONDS, reward -17.804615020751953, action 8\n",
      "EPISODE DONE IN 3.7914199829101562 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 5.692915916442871 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 7.5854103565216064 SECONDS, reward -17.804615020751953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 389\n",
      "EPISODE DONE IN 1.8989906311035156 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 3.8868508338928223 SECONDS, reward -4.7515153884887695, action 7\n",
      "EPISODE DONE IN 5.881000280380249 SECONDS, reward -4.7515153884887695, action 0\n",
      "EPISODE DONE IN 7.868872404098511 SECONDS, reward -4.7515153884887695, action 0\n",
      "\n",
      "\n",
      "EPISODE: 390\n",
      "EPISODE DONE IN 1.8999347686767578 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.79414701461792 SECONDS, reward -27.141239166259766, action 3\n",
      "EPISODE DONE IN 5.81872034072876 SECONDS, reward -10.34347915649414, action 5\n",
      "EPISODE DONE IN 7.843063592910767 SECONDS, reward -10.34347915649414, action 0\n",
      "\n",
      "\n",
      "EPISODE: 391\n",
      "EPISODE DONE IN 2.030571937561035 SECONDS, reward -10.34347915649414, action 0\n",
      "EPISODE DONE IN 3.9351284503936768 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.59641170501709 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.251356601715088 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 392\n",
      "EPISODE DONE IN 1.6611957550048828 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.313772201538086 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.972836256027222 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.630148410797119 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 393\n",
      "EPISODE DONE IN 1.6605243682861328 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3165698051452637 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.9813525676727295 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.6358962059021 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 394\n",
      "EPISODE DONE IN 1.6605117321014404 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5532724857330322 SECONDS, reward -11.829377174377441, action 6\n",
      "EPISODE DONE IN 5.476112604141235 SECONDS, reward -11.829377174377441, action 0\n",
      "EPISODE DONE IN 7.502323865890503 SECONDS, reward -13.519627571105957, action 2\n",
      "\n",
      "\n",
      "EPISODE: 395\n",
      "EPISODE DONE IN 2.026125431060791 SECONDS, reward -13.519627571105957, action 0\n",
      "EPISODE DONE IN 3.921297788619995 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.8196046352386475 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 7.471432685852051 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 396\n",
      "EPISODE DONE IN 1.8970937728881836 SECONDS, reward -44.322898864746094, action 2\n",
      "EPISODE DONE IN 3.7917513847351074 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 5.6931312084198 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 7.595438480377197 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 397\n",
      "EPISODE DONE IN 1.6720075607299805 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3748905658721924 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.09181022644043 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.799316883087158 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 398\n",
      "EPISODE DONE IN 1.9050910472869873 SECONDS, reward -18.279748916625977, action 7\n",
      "EPISODE DONE IN 3.803154230117798 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 5.827941179275513 SECONDS, reward -12.469583511352539, action 6\n",
      "EPISODE DONE IN 7.920185327529907 SECONDS, reward -12.469583511352539, action 0\n",
      "\n",
      "\n",
      "EPISODE: 399\n",
      "EPISODE DONE IN 1.981802225112915 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.9581384658813477 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.678545951843262 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.617386817932129 SECONDS, reward -41.876434326171875, action 2\n",
      "\n",
      "\n",
      "EPISODE: 400\n",
      "EPISODE DONE IN 1.9086050987243652 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 3.9366273880004883 SECONDS, reward -34.401145935058594, action 1\n",
      "EPISODE DONE IN 5.9723875522613525 SECONDS, reward -34.401145935058594, action 0\n",
      "EPISODE DONE IN 7.872414588928223 SECONDS, reward -85.42497253417969, action 0\n",
      "\n",
      "\n",
      "EPISODE: 401\n",
      "EPISODE DONE IN 1.931013584136963 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 3.6390199661254883 SECONDS, reward -10000000.0, action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 5.307826995849609 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.959076881408691 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 402\n",
      "EPISODE DONE IN 1.657651662826538 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3115363121032715 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.970449924468994 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.8616416454315186 SECONDS, reward -85.31786346435547, action 1\n",
      "\n",
      "\n",
      "EPISODE: 403\n",
      "EPISODE DONE IN 1.907646894454956 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.804194927215576 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.708242893218994 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 7.359317302703857 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 404\n",
      "EPISODE DONE IN 1.6582989692687988 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3105366230010986 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.009962320327759 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.693292140960693 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 405\n",
      "EPISODE DONE IN 1.6598241329193115 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3204703330993652 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.9795825481414795 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.630716323852539 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 406\n",
      "EPISODE DONE IN 1.901317834854126 SECONDS, reward -30.819826126098633, action 3\n",
      "EPISODE DONE IN 3.7967100143432617 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 5.701192378997803 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 7.596135377883911 SECONDS, reward -30.819826126098633, action 0\n",
      "\n",
      "\n",
      "EPISODE: 407\n",
      "EPISODE DONE IN 1.663198709487915 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.564697742462158 SECONDS, reward -9.564072608947754, action 7\n",
      "EPISODE DONE IN 5.464237928390503 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 7.358247518539429 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 408\n",
      "EPISODE DONE IN 1.9062554836273193 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.561948776245117 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.224774360656738 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.877822160720825 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 409\n",
      "EPISODE DONE IN 1.6593244075775146 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3129818439483643 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.972264051437378 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.625674247741699 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 410\n",
      "EPISODE DONE IN 1.6594836711883545 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.310372829437256 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.2084503173828125 SECONDS, reward -41.876434326171875, action 2\n",
      "EPISODE DONE IN 7.103787899017334 SECONDS, reward -41.876434326171875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 411\n",
      "EPISODE DONE IN 1.9131848812103271 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 3.9468867778778076 SECONDS, reward -9.33361530303955, action 8\n",
      "EPISODE DONE IN 5.855897903442383 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 7.75081992149353 SECONDS, reward -7.835620880126953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 412\n",
      "EPISODE DONE IN 1.901310682296753 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 3.5526199340820312 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.2126781940460205 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.864237070083618 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 413\n",
      "EPISODE DONE IN 1.6613094806671143 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.31583309173584 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.975025415420532 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.627497911453247 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 414\n",
      "EPISODE DONE IN 1.660583257675171 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.315479278564453 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.973472833633423 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.642839670181274 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 415\n",
      "EPISODE DONE IN 1.7140936851501465 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.367232322692871 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.027239799499512 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.919243335723877 SECONDS, reward -27.10552215576172, action 3\n",
      "\n",
      "\n",
      "EPISODE: 416\n",
      "EPISODE DONE IN 1.899303913116455 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 3.793426513671875 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 5.696300745010376 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 7.6678173542022705 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 417\n",
      "EPISODE DONE IN 1.9822430610656738 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.89011549949646 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.790249347686768 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.683419704437256 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 418\n",
      "EPISODE DONE IN 1.9018974304199219 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.928032159805298 SECONDS, reward -13.499977111816406, action 2\n",
      "EPISODE DONE IN 6.051623582839966 SECONDS, reward -3.5339858531951904, action 2\n",
      "EPISODE DONE IN 8.074991226196289 SECONDS, reward -16.280006408691406, action 0\n",
      "\n",
      "\n",
      "EPISODE: 419\n",
      "EPISODE DONE IN 2.029334545135498 SECONDS, reward -16.280006408691406, action 0\n",
      "EPISODE DONE IN 3.9198243618011475 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 5.578609228134155 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.2333128452301025 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 420\n",
      "EPISODE DONE IN 1.8984150886535645 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.7898812294006348 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.814946889877319 SECONDS, reward -22.187671661376953, action 1\n",
      "EPISODE DONE IN 7.833287239074707 SECONDS, reward -22.187671661376953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 421\n",
      "EPISODE DONE IN 1.9011380672454834 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.7943859100341797 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.456295490264893 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.1081976890563965 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 422\n",
      "EPISODE DONE IN 1.6864941120147705 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4306137561798096 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.260828495025635 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.944906711578369 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 423\n",
      "EPISODE DONE IN 1.702117919921875 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5022799968719482 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.4941887855529785 SECONDS, reward -9.546906471252441, action 7\n",
      "EPISODE DONE IN 7.412623167037964 SECONDS, reward -9.546906471252441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 424\n",
      "EPISODE DONE IN 1.9496674537658691 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.865934371948242 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.583454847335815 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.299230337142944 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 425\n",
      "EPISODE DONE IN 1.9707014560699463 SECONDS, reward -24.511316299438477, action 4\n",
      "EPISODE DONE IN 3.9721641540527344 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 5.997043609619141 SECONDS, reward -24.511316299438477, action 0\n",
      "EPISODE DONE IN 7.992523193359375 SECONDS, reward -24.511316299438477, action 0\n",
      "\n",
      "\n",
      "EPISODE: 426\n",
      "EPISODE DONE IN 1.7498087882995605 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4801437854766846 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.2240071296691895 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.1821465492248535 SECONDS, reward -7.8201141357421875, action 8\n",
      "\n",
      "\n",
      "EPISODE: 427\n",
      "EPISODE DONE IN 1.95369553565979 SECONDS, reward -7.8201141357421875, action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 3.9290578365325928 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.911873817443848 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 7.854816913604736 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 428\n",
      "EPISODE DONE IN 1.9522137641906738 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.9207189083099365 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.830113649368286 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.492462158203125 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 429\n",
      "EPISODE DONE IN 1.7059080600738525 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4310762882232666 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.169665813446045 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.839435338973999 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 430\n",
      "EPISODE DONE IN 1.6937689781188965 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4018983840942383 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.312053680419922 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 7.212910890579224 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 431\n",
      "EPISODE DONE IN 1.9759702682495117 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 3.9521121978759766 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.6719584465026855 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.380079746246338 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 432\n",
      "EPISODE DONE IN 1.7215981483459473 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.380120038986206 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.307764530181885 SECONDS, reward -85.31786346435547, action 1\n",
      "EPISODE DONE IN 7.347332239151001 SECONDS, reward -2.6712796688079834, action 7\n",
      "\n",
      "\n",
      "EPISODE: 433\n",
      "EPISODE DONE IN 2.1121087074279785 SECONDS, reward -2.6712796688079834, action 0\n",
      "EPISODE DONE IN 4.12593412399292 SECONDS, reward -2.6712796688079834, action 0\n",
      "EPISODE DONE IN 6.053527355194092 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.759932279586792 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 434\n",
      "EPISODE DONE IN 1.7379834651947021 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.471771001815796 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.220263957977295 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.943873405456543 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 435\n",
      "EPISODE DONE IN 1.742720127105713 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4367640018463135 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.127366065979004 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.082844495773315 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 436\n",
      "EPISODE DONE IN 1.9943561553955078 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 4.289963006973267 SECONDS, reward -5.150374412536621, action 5\n",
      "EPISODE DONE IN 6.4530029296875 SECONDS, reward -5.150374412536621, action 0\n",
      "EPISODE DONE IN 8.444761037826538 SECONDS, reward -14.94920539855957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 437\n",
      "EPISODE DONE IN 2.14251708984375 SECONDS, reward -5.7081217765808105, action 1\n",
      "EPISODE DONE IN 4.162222623825073 SECONDS, reward -86.46080780029297, action 0\n",
      "EPISODE DONE IN 6.167950868606567 SECONDS, reward -86.46080780029297, action 0\n",
      "EPISODE DONE IN 8.069540739059448 SECONDS, reward -86.46080780029297, action 0\n",
      "\n",
      "\n",
      "EPISODE: 438\n",
      "EPISODE DONE IN 1.7094318866729736 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.421940326690674 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.140335321426392 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.801571369171143 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 439\n",
      "EPISODE DONE IN 1.6868550777435303 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3986010551452637 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.374799728393555 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 7.305649518966675 SECONDS, reward -7.8201141357421875, action 0\n",
      "\n",
      "\n",
      "EPISODE: 440\n",
      "EPISODE DONE IN 2.0688529014587402 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 4.166545391082764 SECONDS, reward -7.8201141357421875, action 0\n",
      "EPISODE DONE IN 5.881244897842407 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.623107194900513 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 441\n",
      "EPISODE DONE IN 1.7546288967132568 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5205743312835693 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.301831483840942 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.034705638885498 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 442\n",
      "EPISODE DONE IN 1.742952585220337 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.464271068572998 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.4436256885528564 SECONDS, reward -14.926665306091309, action 5\n",
      "EPISODE DONE IN 7.361441612243652 SECONDS, reward -14.926665306091309, action 0\n",
      "\n",
      "\n",
      "EPISODE: 443\n",
      "EPISODE DONE IN 1.9287974834442139 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 3.969252586364746 SECONDS, reward -14.926665306091309, action 0\n",
      "EPISODE DONE IN 5.918303728103638 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.683592319488525 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 444\n",
      "EPISODE DONE IN 1.7448818683624268 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.449664354324341 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.117755174636841 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.848258018493652 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 445\n",
      "EPISODE DONE IN 1.6721405982971191 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3905954360961914 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.1131274700164795 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.827517032623291 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 446\n",
      "EPISODE DONE IN 2.063838005065918 SECONDS, reward -86.46080780029297, action 1\n",
      "EPISODE DONE IN 4.068455696105957 SECONDS, reward -86.46080780029297, action 0\n",
      "EPISODE DONE IN 6.198548316955566 SECONDS, reward -11.742783546447754, action 7\n",
      "EPISODE DONE IN 8.31587266921997 SECONDS, reward -11.742783546447754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 447\n",
      "EPISODE DONE IN 2.194925308227539 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 4.403936147689819 SECONDS, reward -10.49156665802002, action 1\n",
      "EPISODE DONE IN 6.90556263923645 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 9.020142793655396 SECONDS, reward -85.42497253417969, action 0\n",
      "\n",
      "\n",
      "EPISODE: 448\n",
      "EPISODE DONE IN 1.9524648189544678 SECONDS, reward -85.42497253417969, action 0\n",
      "EPISODE DONE IN 3.681042432785034 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.46265721321106 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.223975896835327 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 449\n",
      "EPISODE DONE IN 1.7742533683776855 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.7437264919281006 SECONDS, reward -7.835620880126953, action 8\n",
      "EPISODE DONE IN 5.851958990097046 SECONDS, reward -8.778457641601562, action 1\n",
      "EPISODE DONE IN 7.871936798095703 SECONDS, reward -8.778457641601562, action 0\n",
      "\n",
      "\n",
      "EPISODE: 450\n",
      "EPISODE DONE IN 2.1122758388519287 SECONDS, reward -5.87684440612793, action 2\n",
      "EPISODE DONE IN 4.200782299041748 SECONDS, reward -36.82756805419922, action 0\n",
      "EPISODE DONE IN 6.126353979110718 SECONDS, reward -44.322898864746094, action 0\n",
      "EPISODE DONE IN 8.025075435638428 SECONDS, reward -44.322898864746094, action 0\n",
      "\n",
      "\n",
      "EPISODE: 451\n",
      "EPISODE DONE IN 1.9736766815185547 SECONDS, reward -17.804615020751953, action 8\n",
      "EPISODE DONE IN 4.175801992416382 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 6.3290674686431885 SECONDS, reward -17.804615020751953, action 0\n",
      "EPISODE DONE IN 8.354318857192993 SECONDS, reward -17.804615020751953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 452\n",
      "EPISODE DONE IN 1.7031190395355225 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3652265071868896 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.106396436691284 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.8532936573028564 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 1.773982048034668 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5530669689178467 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.335551023483276 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.083042621612549 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 454\n",
      "EPISODE DONE IN 1.7461636066436768 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.439790964126587 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.190114498138428 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.884045600891113 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 455\n",
      "EPISODE DONE IN 1.7400834560394287 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.613433361053467 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.8380537033081055 SECONDS, reward -27.10552215576172, action 3\n",
      "EPISODE DONE IN 7.883000612258911 SECONDS, reward -27.10552215576172, action 0\n",
      "\n",
      "\n",
      "EPISODE: 456\n",
      "EPISODE DONE IN 2.0599329471588135 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 4.103610515594482 SECONDS, reward -27.10552215576172, action 0\n",
      "EPISODE DONE IN 6.170296669006348 SECONDS, reward -85.31786346435547, action 1\n",
      "EPISODE DONE IN 8.265764951705933 SECONDS, reward -85.31786346435547, action 0\n",
      "\n",
      "\n",
      "EPISODE: 457\n",
      "EPISODE DONE IN 2.117457389831543 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 4.175114870071411 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 6.291125059127808 SECONDS, reward -7.8201141357421875, action 8\n",
      "EPISODE DONE IN 8.37792682647705 SECONDS, reward -1.468550443649292, action 4\n",
      "\n",
      "\n",
      "EPISODE: 458\n",
      "EPISODE DONE IN 2.0865957736968994 SECONDS, reward -1.468550443649292, action 0\n",
      "EPISODE DONE IN 4.312854766845703 SECONDS, reward -2.6386945247650146, action 7\n",
      "EPISODE DONE IN 6.425630569458008 SECONDS, reward -7.233112812042236, action 0\n",
      "EPISODE DONE IN 8.592015504837036 SECONDS, reward -11.132439613342285, action 2\n",
      "\n",
      "\n",
      "EPISODE: 459\n",
      "EPISODE DONE IN 2.183560371398926 SECONDS, reward -11.132439613342285, action 0\n",
      "EPISODE DONE IN 4.189106464385986 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 6.257937669754028 SECONDS, reward -41.876434326171875, action 0\n",
      "EPISODE DONE IN 8.063968420028687 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 460\n",
      "EPISODE DONE IN 1.7066943645477295 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.383424997329712 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.039949417114258 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.981069564819336 SECONDS, reward -9.546906471252441, action 7\n",
      "\n",
      "\n",
      "EPISODE: 461\n",
      "EPISODE DONE IN 1.9241869449615479 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.8856818675994873 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.790965795516968 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 7.438305854797363 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 462\n",
      "EPISODE DONE IN 1.653761863708496 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3008880615234375 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.974342584609985 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.712437629699707 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 463\n",
      "EPISODE DONE IN 1.738128900527954 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.671508550643921 SECONDS, reward -27.141239166259766, action 3\n",
      "EPISODE DONE IN 5.61557149887085 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 7.53849720954895 SECONDS, reward -27.141239166259766, action 0\n",
      "\n",
      "\n",
      "EPISODE: 464\n",
      "EPISODE DONE IN 2.0473315715789795 SECONDS, reward -14.264087677001953, action 3\n",
      "EPISODE DONE IN 4.036741018295288 SECONDS, reward -5.949560642242432, action 7\n",
      "EPISODE DONE IN 6.1095263957977295 SECONDS, reward -5.949560642242432, action 0\n",
      "EPISODE DONE IN 8.098528385162354 SECONDS, reward -5.949560642242432, action 0\n",
      "\n",
      "\n",
      "EPISODE: 465\n",
      "EPISODE DONE IN 1.918834924697876 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.6824557781219482 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.446593999862671 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.237696647644043 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 466\n",
      "EPISODE DONE IN 2.107550621032715 SECONDS, reward -30.819826126098633, action 3\n",
      "EPISODE DONE IN 4.214194059371948 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 6.447974443435669 SECONDS, reward -13.982704162597656, action 4\n",
      "EPISODE DONE IN 8.561665058135986 SECONDS, reward -13.982704162597656, action 0\n",
      "\n",
      "\n",
      "EPISODE: 467\n",
      "EPISODE DONE IN 1.9091780185699463 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 3.799405097961426 SECONDS, reward -19.538095474243164, action 0\n",
      "EPISODE DONE IN 5.454081773757935 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.1030943393707275 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 468\n",
      "EPISODE DONE IN 1.6874492168426514 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3355228900909424 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.01111102104187 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.711827039718628 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 469\n",
      "EPISODE DONE IN 1.7154507637023926 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.56723952293396 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.632617712020874 SECONDS, reward -11.80997371673584, action 6\n",
      "EPISODE DONE IN 7.554873943328857 SECONDS, reward -11.80997371673584, action 0\n",
      "\n",
      "\n",
      "EPISODE: 470\n",
      "EPISODE DONE IN 2.0207412242889404 SECONDS, reward -12.469583511352539, action 7\n",
      "EPISODE DONE IN 4.043078899383545 SECONDS, reward -12.469583511352539, action 0\n",
      "EPISODE DONE IN 6.010893821716309 SECONDS, reward -18.279748916625977, action 0\n",
      "EPISODE DONE IN 7.89969801902771 SECONDS, reward -18.279748916625977, action 0\n",
      "\n",
      "\n",
      "EPISODE: 471\n",
      "EPISODE DONE IN 1.664677619934082 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.417428493499756 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.474584341049194 SECONDS, reward -9.546906471252441, action 7\n",
      "EPISODE DONE IN 7.395475149154663 SECONDS, reward -9.546906471252441, action 0\n",
      "\n",
      "\n",
      "EPISODE: 472\n",
      "EPISODE DONE IN 1.9819495677947998 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.890395164489746 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.547671318054199 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.196721315383911 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 473\n",
      "EPISODE DONE IN 1.656212568283081 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.5523555278778076 SECONDS, reward -9.564072608947754, action 7\n",
      "EPISODE DONE IN 5.452972412109375 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 7.344579219818115 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 474\n",
      "EPISODE DONE IN 1.990159034729004 SECONDS, reward -5.949560642242432, action 3\n",
      "EPISODE DONE IN 3.8791048526763916 SECONDS, reward -30.819826126098633, action 0\n",
      "EPISODE DONE IN 5.8965723514556885 SECONDS, reward -14.352012634277344, action 7\n",
      "EPISODE DONE IN 7.93951678276062 SECONDS, reward -14.352012634277344, action 0\n",
      "\n",
      "\n",
      "EPISODE: 475\n",
      "EPISODE DONE IN 1.8989934921264648 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 3.8382701873779297 SECONDS, reward -9.546906471252441, action 0\n",
      "EPISODE DONE IN 5.548515796661377 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.197378158569336 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 476\n",
      "EPISODE DONE IN 1.6561338901519775 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3051271438598633 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 4.962651014328003 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.851348876953125 SECONDS, reward -11.80997371673584, action 6\n",
      "\n",
      "\n",
      "EPISODE: 477\n",
      "EPISODE DONE IN 1.9001832008361816 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 3.7930476665496826 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 5.689780950546265 SECONDS, reward -11.80997371673584, action 0\n",
      "EPISODE DONE IN 7.3381898403167725 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 478\n",
      "EPISODE DONE IN 1.6593031883239746 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.3353466987609863 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.010386228561401 SECONDS, reward -10000000.0, action 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE IN 6.683754920959473 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 479\n",
      "EPISODE DONE IN 1.971386432647705 SECONDS, reward -24.511316299438477, action 4\n",
      "EPISODE DONE IN 4.019328832626343 SECONDS, reward -11.93644905090332, action 3\n",
      "EPISODE DONE IN 6.07184100151062 SECONDS, reward -11.93644905090332, action 0\n",
      "EPISODE DONE IN 8.118961334228516 SECONDS, reward -11.93644905090332, action 0\n",
      "\n",
      "\n",
      "EPISODE: 480\n",
      "EPISODE DONE IN 1.9011330604553223 SECONDS, reward -27.141239166259766, action 0\n",
      "EPISODE DONE IN 3.5887959003448486 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.260886192321777 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.916118144989014 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 481\n",
      "EPISODE DONE IN 1.655099868774414 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.544405937194824 SECONDS, reward -14.94920539855957, action 5\n",
      "EPISODE DONE IN 5.447286605834961 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 7.344816446304321 SECONDS, reward -14.94920539855957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 482\n",
      "EPISODE DONE IN 1.8983893394470215 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.5539920330047607 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.207942485809326 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.899573564529419 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 483\n",
      "EPISODE DONE IN 1.7174460887908936 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4195075035095215 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.1381824016571045 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.7873523235321045 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 484\n",
      "EPISODE DONE IN 1.6671874523162842 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.346545696258545 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.065576076507568 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 6.780814170837402 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 485\n",
      "EPISODE DONE IN 1.7116429805755615 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.7599804401397705 SECONDS, reward -7.835620880126953, action 8\n",
      "EPISODE DONE IN 5.848013639450073 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 7.76329779624939 SECONDS, reward -7.835620880126953, action 0\n",
      "\n",
      "\n",
      "EPISODE: 486\n",
      "EPISODE DONE IN 2.0607426166534424 SECONDS, reward -7.835620880126953, action 0\n",
      "EPISODE DONE IN 3.740903854370117 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.530029058456421 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.232126712799072 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 487\n",
      "EPISODE DONE IN 1.981626033782959 SECONDS, reward -21.154136657714844, action 5\n",
      "EPISODE DONE IN 3.9514570236206055 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 5.9660115242004395 SECONDS, reward -21.154136657714844, action 0\n",
      "EPISODE DONE IN 7.90234899520874 SECONDS, reward -21.154136657714844, action 0\n",
      "\n",
      "\n",
      "EPISODE: 488\n",
      "EPISODE DONE IN 1.7235517501831055 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.4295358657836914 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.404947996139526 SECONDS, reward -85.31786346435547, action 1\n",
      "EPISODE DONE IN 7.415439605712891 SECONDS, reward -85.31786346435547, action 0\n",
      "\n",
      "\n",
      "EPISODE: 489\n",
      "EPISODE DONE IN 2.011849880218506 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 3.985882043838501 SECONDS, reward -85.31786346435547, action 0\n",
      "EPISODE DONE IN 5.738812208175659 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.4310808181762695 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 490\n",
      "EPISODE DONE IN 1.7824442386627197 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.51171875 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.262283086776733 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.016404151916504 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 491\n",
      "EPISODE DONE IN 1.7900092601776123 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.719942569732666 SECONDS, reward -9.564072608947754, action 7\n",
      "EPISODE DONE IN 5.631714105606079 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 7.590891361236572 SECONDS, reward -9.564072608947754, action 0\n",
      "\n",
      "\n",
      "EPISODE: 492\n",
      "EPISODE DONE IN 1.9935696125030518 SECONDS, reward -9.564072608947754, action 0\n",
      "EPISODE DONE IN 3.9822299480438232 SECONDS, reward -14.94920539855957, action 5\n",
      "EPISODE DONE IN 5.999746561050415 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 8.01348066329956 SECONDS, reward -14.94920539855957, action 0\n",
      "\n",
      "\n",
      "EPISODE: 493\n",
      "EPISODE DONE IN 2.0097556114196777 SECONDS, reward -14.94920539855957, action 0\n",
      "EPISODE DONE IN 3.7360401153564453 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.494099378585815 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 7.207372188568115 SECONDS, reward -10000000.0, action 0\n",
      "\n",
      "\n",
      "EPISODE: 494\n",
      "EPISODE DONE IN 1.716759204864502 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 3.438631057739258 SECONDS, reward -10000000.0, action 0\n",
      "EPISODE DONE IN 5.188894748687744 SECONDS, reward -10000000.0, action 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f15a923ee0e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrewards_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-ffc16bea6665>\u001b[0m in \u001b[0;36mmake_action\u001b[0;34m(self, bs_index, action)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs_power\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpowers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbit_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbit_rate_from_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-ffc16bea6665>\u001b[0m in \u001b[0;36mbit_rate_from_grid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbit_rate_from_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mmax_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbm_to_watt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpowers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0minterference_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbm_to_watt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpowers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_power\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bit_rate_sinr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterference_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-ffc16bea6665>\u001b[0m in \u001b[0;36mdbm_to_watt\u001b[0;34m(self, dbm)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdbm_to_watt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpath_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rewards_history = []\n",
    "for episode in range(num_episodes):\n",
    "    timer = time.time()\n",
    "    print(\"\\n\\nEPISODE:\", episode+1)\n",
    "    \n",
    "    env.apply_blackouts(episode+1)\n",
    "    \n",
    "    for i in range(env.n_bs):\n",
    "        state = torch.tensor(env.get_state(i), dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "        action = agent.select_action(state, policy_net)\n",
    "        _, action, next_state, reward = env.make_action(i, action)\n",
    "        \n",
    "        rewards_history.append(reward)\n",
    "\n",
    "        reward = torch.tensor([reward], dtype=torch.float)\n",
    "        next_state = torch.tensor(next_state, dtype=torch.float).unsqueeze(0)\n",
    "        memory.push(Experience(state, action, next_state, reward))\n",
    "        state = next_state\n",
    "\n",
    "        if memory.can_provide_sample(batch_size):\n",
    "            exps = memory.sample(batch_size)\n",
    "            states, actions, next_states, rewards = extract_tensors(exps)\n",
    "            current_q_values = QValues.get_current(policy_net, states, actions)\n",
    "            next_q_values = QValues.get_next(target_net, next_states)\n",
    "            target_q_values = (next_q_values * gamma) + rewards\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.smooth_l1_loss(\n",
    "                current_q_values, target_q_values.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if episode % target_update == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        print(\"EPISODE DONE IN {} SECONDS, reward {}, action {}\".format(time.time() - timer, reward[0], action[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28aee0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1975 \n",
      " 10 episode moving avg: -6000005.5\n"
     ]
    }
   ],
   "source": [
    "plot(rewards_history, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c6aca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10000000.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09ceeef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x7f7f06512430>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAStElEQVR4nO3df6zd9X3f8edrpkEjTYYpDBmbDCcykSDaHLiiSAtRpnT8UhdIJ6VGUyFpUicqSI22qYJFWlBRpPUHjYTaETmLBUwphI5S/Adp4qAqaNJIciEuGALhmoCw5dgUqlDNESvw3h/nc8sXc699f5x77kWf50P66n7P+/vjvM/3XL/u8ef7PeekqpAk9eGfrHYDkqTJMfQlqSOGviR1xNCXpI4Y+pLUkRNWu4HjyUmnFieftdptSNLbx8GH/7aqTptr0ZoPfU4+Cz4zvdpdSNLbx015br5FDu9IUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOHDf0k+xMcjjJ3kHtG0n2tOnZJHta/awkPx8s+8pgm/OTPJZkJsktSbIij0iSNK8TFrDObcCfAHfMFqrq12fnk9wM/Gyw/r6q2jrHfm4Ffgv4HnA/cCnwzUV3LElasuO+0q+qB4GX5lrWXq1/ArjzWPtIsgF4d1U9VFXF6A/IlYvuVpK0LMsd078IOFRVTw9qm5P8MMl3k1zUahuB/YN19rfanJJsTzKdZJojLyyzRUnSrIUM7xzLVbz5Vf5B4D1V9WKS84G/THLuYndaVTuAHQA5Y6qW2aMkqVly6Cc5Afg14PzZWlW9ArzS5h9Osg84GzgAbBpsvqnVJEkTtJzhnV8Bnqyqfxy2SXJaknVt/r3AFuCZqjoIvJzkwnYe4GrgvmXctyRpCRZyyeadwP8B3p9kf5JPt0XbeOsJ3A8Dj7ZLOP8X8Lmqmj0J/NvA/wBmgH145Y4kTdxxh3eq6qp56p+co3YPcM88608DH1hkf5KkMfIduZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrKQ78jdmeRwkr2D2o1JDiTZ06bLB8tuSDKT5Kkklwzql7baTJLrx/9QJEnHs5BX+rcBl85R/3JVbW3T/QBJzmH0henntm3+e5J1SdYBfwpcBpwDXNXWlSRN0EK+GP3BJGctcH9XAHdV1SvAT5LMABe0ZTNV9QxAkrvauk8svmVJ0lItZ0z/uiSPtuGf9a22EXh+sM7+VpuvLkmaoKWG/q3A+4CtwEHg5nE1BJBke5LpJNMceWGcu5akri0p9KvqUFW9VlWvA1/ljSGcA8CZg1U3tdp89fn2v6OqpqpqipNOW0qLkqQ5LCn0k2wY3Pw4MHtlzy5gW5ITk2wGtgDfB34AbEmyOck7GJ3s3bX0tiVJS3HcE7lJ7gQ+ApyaZD/wReAjSbYCBTwLfBagqh5PcjejE7SvAtdW1WttP9cB3wLWATur6vFxPxhJ0rGlqla7h2PKGVPFZ6ZXuw1Jevu4KQ9X1dRci3xHriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSR44Z+kp1JDifZO6j9YZInkzya5N4kJ7f6WUl+nmRPm74y2Ob8JI8lmUlyS5KsyCOSJM1rIa/0bwMuPaq2G/hAVf1L4MfADYNl+6pqa5s+N6jfCvwWsKVNR+9TkrTCjhv6VfUg8NJRtW9X1avt5kPApmPtI8kG4N1V9VBVFXAHcOWSOpYkLdk4xvR/E/jm4PbmJD9M8t0kF7XaRmD/YJ39rTanJNuTTCeZ5sgLY2hRkgRwwnI2TvIF4FXg6610EHhPVb2Y5HzgL5Ocu9j9VtUOYAdAzpiq5fQoSXrDkkM/ySeBXwU+2oZsqKpXgFfa/MNJ9gFnAwd48xDQplaTJE3QkoZ3klwK/C7wsao6MqiflmRdm38voxO2z1TVQeDlJBe2q3auBu5bdveSpEU57iv9JHcCHwFOTbIf+CKjq3VOBHa3Ky8falfqfBj4vST/ALwOfK6qZk8C/zajK4H+KaNzAMPzAJKkCThu6FfVVXOUvzbPuvcA98yzbBr4wKK6kySNle/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkQWFfpKdSQ4n2TuonZJkd5Kn28/1rZ4ktySZSfJokvMG21zT1n86yTXjfziSpGNZ6Cv924BLj6pdDzxQVVuAB9ptgMuALW3aDtwKoz8SjL5U/ZeBC4Avzv6hkCRNxoJCv6oeBF46qnwFcHubvx24clC/o0YeAk5OsgG4BNhdVS9V1d8Bu3nrHxJJ0gpazpj+6VV1sM3/FDi9zW8Enh+st7/V5qu/RZLtSaaTTHPkhWW0KEkaGsuJ3KoqoMaxr7a/HVU1VVVTnHTauHYrSd1bTugfasM2tJ+HW/0AcOZgvU2tNl9dkjQhywn9XcDsFTjXAPcN6le3q3guBH7WhoG+BVycZH07gXtxq0mSJuSEhayU5E7gI8CpSfYzugrnvwF3J/k08Bzwibb6/cDlwAxwBPgUQFW9lOQm4Adtvd+rqqNPDkuSVlBGw/FrV86YKj4zvdptSNLbx015uKqm5lrkO3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkyaGf5P1J9gyml5N8PsmNSQ4M6pcPtrkhyUySp5JcMp6HIElaqAV9MfpcquopYCtAknXAAeBeRl+E/uWq+qPh+knOAbYB5wJnAN9JcnZVvbbUHiRJizOu4Z2PAvuq6rljrHMFcFdVvVJVPwFmgAvGdP+SpAUYV+hvA+4c3L4uyaNJdiZZ32obgecH6+xvtbdIsj3JdJJpjrwwphYlScsO/STvAD4G/Hkr3Qq8j9HQz0Hg5sXus6p2VNVUVU1x0mnLbVGS1Izjlf5lwCNVdQigqg5V1WtV9TrwVd4YwjkAnDnYblOrSZImZByhfxWDoZ0kGwbLPg7sbfO7gG1JTkyyGdgCfH8M9y9JWqAlX70DkOSdwL8FPjso/0GSrUABz84uq6rHk9wNPAG8ClzrlTuSNFnLCv2q+r/ALx1V+41jrP8l4EvLuU9J0tL5jlxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR1ZdugneTbJY0n2JJlutVOS7E7ydPu5vtWT5JYkM0keTXLecu9fkrRw43ql/2+qamtVTbXb1wMPVNUW4IF2G+AyYEubtgO3jun+JUkLsFLDO1cAt7f524ErB/U7auQh4OQkG1aoB0nSUcYR+gV8O8nDSba32ulVdbDN/xQ4vc1vBJ4fbLu/1d4kyfYk00mmOfLCGFqUJAGcMIZ9fKiqDiT558DuJE8OF1ZVJanF7LCqdgA7AHLG1KK2lSTNb9mv9KvqQPt5GLgXuAA4NDts034ebqsfAM4cbL6p1SRJE7Cs0E/yziTvmp0HLgb2AruAa9pq1wD3tfldwNXtKp4LgZ8NhoEkSStsucM7pwP3Jpnd159V1V8l+QFwd5JPA88Bn2jr3w9cDswAR4BPLfP+JUmLsKzQr6pngH81R/1F4KNz1Au4djn3KUlaOt+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI0sO/SRnJvnrJE8keTzJ77T6jUkOJNnTpssH29yQZCbJU0kuGccDkCQt3HK+I/dV4D9V1SNJ3gU8nGR3W/blqvqj4cpJzgG2AecCZwDfSXJ2Vb22jB4kSYuw5Ff6VXWwqh5p838P/AjYeIxNrgDuqqpXquonwAxwwVLvX5K0eGMZ009yFvBB4HutdF2SR5PsTLK+1TYCzw8228+x/0hIksZs2aGf5BeBe4DPV9XLwK3A+4CtwEHg5iXsc3uS6STTHHlhuS1KkpplhX6SX2AU+F+vqr8AqKpDVfVaVb0OfJU3hnAOAGcONt/Uam9RVTuqaqqqpjjptOW0KEkaWM7VOwG+Bvyoqv54UN8wWO3jwN42vwvYluTEJJuBLcD3l3r/kqTFW87VO/8a+A3gsSR7Wu2/AFcl2QoU8CzwWYCqejzJ3cATjK78udYrdyRpspYc+lX1v4HMsej+Y2zzJeBLS71PSdLy+I5cSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMTD/0klyZ5KslMkusnff+S1LOJhn6SdcCfApcB5wBXJTlnkj1IUs8m/Ur/AmCmqp6pqv8H3AVcMeEeJKlbJ0z4/jYCzw9u7wd++eiVkmwHtrebr3BT9k6gt+U4Ffjb1W5iAexzvOxzvOxzfP7FfAsmHfoLUlU7gB0ASaaramqVWzqmt0OPYJ/jZp/jZZ+TMenhnQPAmYPbm1pNkjQBkw79HwBbkmxO8g5gG7Brwj1IUrcmOrxTVa8muQ74FrAO2FlVjx9nsx0r39myvR16BPscN/scL/ucgFTVavcgSZoQ35ErSR0x9CWpI2s29NfSxzUkOTPJXyd5IsnjSX6n1W9MciDJnjZdPtjmhtb7U0kumWCvzyZ5rPUz3WqnJNmd5On2c32rJ8ktrc9Hk5w3oR7fPzhme5K8nOTza+F4JtmZ5HDyxntDlnL8klzT1n86yTUT6PEPkzzZ+rg3ycmtflaSnw+O6VcG25zffldm2uPIBPpc9HO80lkwT5/fGPT4bJI9rb5qx3NsqmrNTYxO8u4D3gu8A/gb4JxV7GcDcF6bfxfwY0YfI3Ej8J/nWP+c1vOJwOb2WNZNqNdngVOPqv0BcH2bvx74/TZ/OfBNIMCFwPdW6bn+KaM3k6z68QQ+DJwH7F3q8QNOAZ5pP9e3+fUr3OPFwAlt/vcHPZ41XO+o/Xy/9Z32OC6bwLFc1HM8iSyYq8+jlt8M/NfVPp7jmtbqK/019XENVXWwqh5p838P/IjRu4vncwVwV1W9UlU/AWYYPabVcgVwe5u/HbhyUL+jRh4CTk6yYcK9fRTYV1XPHWOdiR3PqnoQeGmO+1/M8bsE2F1VL1XV3wG7gUtXsseq+nZVvdpuPsToPTDzan2+u6oeqlFi3TF4XCvW5zHM9xyveBYcq8/2av0TwJ3H2sckjue4rNXQn+vjGo4VshOT5Czgg8D3Wum69l/qnbP/7Wd1+y/g20kezujjLABOr6qDbf6nwOltfi0c5228+R/UWjuesPjjt9r9/iajV5qzNif5YZLvJrmo1Ta2vmZNssfFPMerfSwvAg5V1dOD2lo7nouyVkN/TUryi8A9wOer6mXgVuB9wFbgIKP/Bq62D1XVeYw+yfTaJB8eLmyvQtbEdboZvUHvY8Cft9JaPJ5vspaO31ySfAF4Ffh6Kx0E3lNVHwT+I/BnSd69Wv3xNniOj3IVb35RstaO56Kt1dBfcx/XkOQXGAX+16vqLwCq6lBVvVZVrwNf5Y0hh1Xrv6oOtJ+HgXtbT4dmh23az8Or3WdzGfBIVR2CtXk8m8Uev1XpN8kngV8F/kP740QbLnmxzT/MaHz87NbPcAhoIj0u4Tletec+yQnArwHfmK2tteO5FGs19NfUxzW0cb2vAT+qqj8e1Ifj3x8HZs/+7wK2JTkxyWZgC6OTPCvd5zuTvGt2ntHJvb2tn9krSK4B7hv0eXW7CuVC4GeDYYxJeNOrqLV2PAcWe/y+BVycZH0bvri41VZMkkuB3wU+VlVHBvXTMvoeC5K8l9Gxe6b1+XKSC9vv99WDx7WSfS72OV7NLPgV4Mmq+sdhm7V2PJdktc8kzzcxujLix4z+kn5hlXv5EKP/0j8K7GnT5cD/BB5r9V3AhsE2X2i9P8WEzuIzusLhb9r0+OxxA34JeAB4GvgOcEqrh9GX2uxrj2Nqgsf0ncCLwD8b1Fb9eDL6I3QQ+AdG47KfXsrxYzSuPtOmT02gxxlGY9+zv59faev++/a7sAd4BPh3g/1MMQrdfcCf0N6hv8J9Lvo5XuksmKvPVr8N+NxR667a8RzX5McwSFJH1urwjiRpBRj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSP/H0v+VCr3cunQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.contourf(env.points[:,:,0], env.points[:,:,1], env.bit_rate, 100, cmap = plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "623f5b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf -inf -inf -inf]\n"
     ]
    }
   ],
   "source": [
    "print(env.bs_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50535460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000., 2000., 3000., 4000., 5000.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1000, 5000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09797a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
